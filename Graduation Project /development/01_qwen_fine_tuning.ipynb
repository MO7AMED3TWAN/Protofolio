{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuZj8xQlfz0r"
      },
      "source": [
        "# Import the requierments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K8cR70WFaQpS"
      },
      "outputs": [],
      "source": [
        "# !pip install -qU transformers==4.51.3 datasets==3.2.0\n",
        "# !pip install -qU openai==1.61.0 wandb\n",
        "# !pip install -qU json-repair==0.29.1 numpy chardet\n",
        "# !pip install -qU vllm==0.7.2 optimum==1.24.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swa6hh4ZaQpT",
        "outputId": "a2f692ae-ae47-4725-8139-71faa09e5741"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmo7amed3twan\u001b[0m (\u001b[33mmo7amed3twan-kafr-el-sheikh-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `Qwen 0.5` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `Qwen 0.5`\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import wandb\n",
        "\n",
        "wandb.login(key=userdata.get('wandb'))\n",
        "hf_token = userdata.get('huggingface')\n",
        "!huggingface-cli login --token {hf_token}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IxkjKk3caQpU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from os.path import join\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import requests\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Literal\n",
        "from datetime import datetime\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aJ-gLTRf3nI"
      },
      "source": [
        "# Prepare The Data For Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "A1aOIf57aQpV"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/Data\"\n",
        "\n",
        "device = \"cuda\"\n",
        "\n",
        "base_model_id = \"Qwen/Qwen2.5-0.5B\"\n",
        "\n",
        "# YoussefHosni/Qwen2.5-0.5b-arabic-2B-toekn-finetuned-model\n",
        "\n",
        "# def parse_json(text):\n",
        "#     try:\n",
        "#         return json_repair.loads(text)\n",
        "#     except:\n",
        "#         return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93gnVs9KaQpa"
      },
      "source": [
        "### Load The Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "4Cmb5ZVWaQpb"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype = None\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y13Zf5G_aQpc"
      },
      "source": [
        "#### **Show The Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g8ssjH3AaQpc",
        "outputId": "bc71aa31-2e2e-4d26-9155-9c18bf299fc0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
              "    (rotary_emb): Qwen2RotaryEmbedding()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IhZJy5SaQpd"
      },
      "source": [
        "### **Apply My Schema On The Model Chat Templet**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "MDQT6irrhEZ3"
      },
      "outputs": [],
      "source": [
        "qa_message = [{\"role\": \"user\", \"content\": \"ما هي المظاهر الاقتصادية فى دولة مصر ؟\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "HgUX2y2RaQpd"
      },
      "outputs": [],
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    qa_message,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "-HuM1Ze2iVLL",
        "outputId": "920548ee-1e5e-41ee-9694-2b83902f620c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nما هي المظاهر الاقتصادية فى دولة مصر ؟<|im_end|>\\n<|im_start|>assistant\\n'"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6PjrQ7waQpe"
      },
      "source": [
        "### **Start encode the prompt to IDS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "rHsjm7ataQpe"
      },
      "outputs": [],
      "source": [
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pIv0TIz-jXru",
        "outputId": "b0dad20d-cdb0-4bcd-b325-51077fd0c329"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n",
              "         151645,    198, 151644,    872,    198, 124009, 128420,  53479,  92381,\n",
              "         125387, 136251, 128393,  44330, 125138, 128748,   8803,    253, 151645,\n",
              "            198, 151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwIEdWfwaQpf"
      },
      "source": [
        "### **Generate The Response In IDS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wR4aJJbUaQpf",
        "outputId": "1b09bbab-3b17-4f54-ae1b-feadfbe81a3c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "generated_ids = model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=2048,\n",
        "    do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48mWJKI3jcB4",
        "outputId": "d7749855-913c-4790-bd1d-aa48ba34cbe3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[151644,   8948,    198,  ...,  73274, 135022, 139013]],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MfedtDJaQpg"
      },
      "source": [
        "### **Here I Pick up just The Response of the model in also IDS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "vUGro7E8aQpg"
      },
      "outputs": [],
      "source": [
        "generated_ids = [\n",
        "    output_ids[len(input_ids):]\n",
        "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQyfSp53jgME",
        "outputId": "7ca4b790-69e4-441c-c1cd-6e15873ed8df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([124130, 126198,  73274,  ...,  73274, 135022, 139013], device='cuda:0')]"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "generated_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtSGhiQCaQpg"
      },
      "source": [
        "### **Last Step that I Decode The IDS Into Text**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "9q1p895uaQpg"
      },
      "outputs": [],
      "source": [
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGTatVq0aQpg",
        "outputId": "637d1397-d78b-4124-aec7-b3fa703e35e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "كل ما يخص الاقتصاد المصري هو تراجع معدلات النمو في عام 2007 و2008 وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدلات النمو في عام 2007 2,5% و2008 2,7% وانه لم يتجاوز معدل\n"
          ]
        }
      ],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEuTvkOnmFB5"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k44-yv07aQph"
      },
      "source": [
        "# Now Let Us Finetuning Our Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PumhlLfGaQph",
        "outputId": "1caabb3b-76bc-43c5-89ce-d7845a415a45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/kaggle/working/youtube-resources/llm-finetuning/dataset/DATA.jsonl'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sft_data_path = join(data_dir, \"dataset\", \"DATA.jsonl\")\n",
        "sft_data_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVebqF9haQpj"
      },
      "outputs": [],
      "source": [
        "# # Configure LLaMA-Factory for the new datasets\n",
        "\n",
        "# # update /content/LLaMA-Factory/data/dataset_info.json and append\n",
        "# ```\n",
        "   \"QAtrain\": {\n",
        "        \"file_name\": \"/kaggle/input/hadiths/llamafactory-finetune-data-v2/train.json\",\n",
        "        \"columns\": {\n",
        "            \"prompt\": \"instruction\",\n",
        "            \"query\": \"input\",\n",
        "            \"response\": \"output\",\n",
        "            \"system\": \"system\",\n",
        "            \"history\": \"history\"\n",
        "        }\n",
        "    },\n",
        "    \"QAval\": {\n",
        "        \"file_name\": \"/kaggle/input/hadiths/llamafactory-finetune-data-v2/val.json\",\n",
        "        \"columns\": {\n",
        "            \"prompt\": \"instruction\",\n",
        "            \"query\": \"input\",\n",
        "            \"response\": \"output\",\n",
        "            \"system\": \"system\",\n",
        "            \"history\": \"history\"\n",
        "        }\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMp-J0cU7uLS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"TRANSFORMERS_NO_TQDM\"] = \"1\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3VZ7NXBaQpk",
        "outputId": "c29289b5-e987-48b4-d765-f0b30e6d2518"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing /kaggle/working/LLaMA-Factory/examples/train_lora/QA.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile /kaggle/working/LLaMA-Factory/examples/train_lora/QA.yaml\n",
        "\n",
        "### model\n",
        "model_name_or_path: Qwen/Qwen2.5-0.5B\n",
        "trust_remote_code: true\n",
        "\n",
        "### method\n",
        "stage: sft\n",
        "do_train: true\n",
        "finetuning_type: lora\n",
        "lora_rank: 64\n",
        "lora_target: all\n",
        "\n",
        "### dataset\n",
        "dataset: QAtrain\n",
        "eval_dataset: QAval\n",
        "template: qwen\n",
        "cutoff_len: 4096\n",
        "max_samples: 50\n",
        "overwrite_cache: true\n",
        "preprocessing_num_workers: 32\n",
        "\n",
        "### output\n",
        "resume_from_checkpoint: \"/kaggle/working/Models_Ouput2/last-checkpoint\"\n",
        "output_dir: \"/kaggle/working/Models_Ouput2\"\n",
        "logging_steps: 50\n",
        "save_steps: 500\n",
        "plot_loss: true\n",
        "overwrite_output_dir: true\n",
        "\n",
        "### train\n",
        "per_device_train_batch_size: 1\n",
        "gradient_accumulation_steps: 4\n",
        "learning_rate: 1.0e-4\n",
        "num_train_epochs: 3.0\n",
        "lr_scheduler_type: cosine\n",
        "warmup_ratio: 0.1\n",
        "bf16: true # full\n",
        "ddp_timeout: 180000000\n",
        "\n",
        "### eval\n",
        "val_size: 0.1\n",
        "per_device_eval_batch_size: 1\n",
        "eval_strategy: epoch\n",
        "eval_steps: 500\n",
        "\n",
        "report_to: wandb\n",
        "run_name: Qwennn\n",
        "\n",
        "push_to_hub: true\n",
        "export_hub_model_id: \"Atwan/QWEN_Arabic_RAG\"\n",
        "hub_private_repo: true\n",
        "hub_strategy: checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg8gmGbLf_gi",
        "outputId": "cd558930-ede4-4dd0-b996-1824fa0684ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/working\n"
          ]
        }
      ],
      "source": [
        "%cd /kaggle/working"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGK1-EeJaQpk",
        "outputId": "e347a662-b438-4405-c9cb-dbe39f8cd1b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-05-16 17:45:07.130929: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\r\n",
            "E0000 00:00:1747417507.155022     384 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
            "E0000 00:00:1747417507.162282     384 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "[INFO|2025-05-16 17:45:14] llamafactory.hparams.parser:401 >> Process rank: 0, world size: 1, device: cuda:0, distributed training: False, compute dtype: torch.bfloat16\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:14,982 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:14,982 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:14,982 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:14,982 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:14,982 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:14,982 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:14,983 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|tokenization_utils_base.py:2323] 2025-05-16 17:45:15,456 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 17:45:16,615 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 17:45:16,617 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:16,813 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:16,813 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:16,813 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:16,813 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:16,813 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:16,813 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2060] 2025-05-16 17:45:16,813 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|tokenization_utils_base.py:2323] 2025-05-16 17:45:17,279 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|2025-05-16 17:45:17] llamafactory.data.loader:143 >> Loading dataset /kaggle/input/hadiths/llamafactory-finetune-data-v2/train.json...\n",
            "Setting num_proc from 32 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 24160 examples [00:01, 16238.88 examples/s]\n",
            "Converting format of dataset (num_proc=32): 100%|█| 24160/24160 [00:02<00:00, 11\n",
            "[INFO|2025-05-16 17:45:22] llamafactory.data.loader:143 >> Loading dataset /kaggle/input/hadiths/llamafactory-finetune-data-v2/val.json...\n",
            "Setting num_proc from 32 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
            "Generating train split: 6040 examples [00:00, 27098.81 examples/s]\n",
            "Converting format of dataset (num_proc=32): 100%|█| 6040/6040 [00:00<00:00, 6486\n",
            "Running tokenizer on dataset (num_proc=32): 100%|█| 24160/24160 [00:30<00:00, 78\n",
            "training example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 458, 15235, 17847, 27076, 304, 8660, 323, 25021, 15203, 23864, 410, 624, 2610, 686, 387, 2661, 264, 3405, 5435, 311, 264, 23864, 410, 304, 34117, 624, 7771, 3383, 374, 311, 4226, 279, 3405, 9355, 11, 3529, 285, 974, 11, 323, 29257, 3118, 389, 15203, 33125, 624, 65354, 304, 34117, 323, 1795, 279, 1852, 16232, 323, 7990, 438, 28824, 15203, 40841, 13, 151645, 198, 151644, 872, 198, 10176, 125352, 55891, 52704, 14558, 27910, 124269, 27910, 73771, 20064, 27910, 123829, 52704, 8532, 64604, 124269, 27910, 73771, 124082, 52704, 124392, 52704, 14558, 27910, 73771, 25871, 64604, 37524, 27910, 31382, 13325, 64604, 73771, 11071, 64604, 125463, 64604, 53479, 64604, 20064, 59397, 14293, 27910, 20931, 27910, 65398, 27910, 25871, 64604, 135635, 27910, 12653, 27910, 123829, 52704, 13325, 53479, 64604, 46586, 27910, 124429, 41593, 27910, 25871, 23364, 52704, 11798, 27910, 123961, 27910, 13325, 52704, 126259, 52704, 6, 80970, 39434, 27910, 20064, 64604, 21360, 64604, 73771, 123920, 124695, 59397, 12653, 27910, 47632, 27910, 68785, 128843, 27910, 73771, 16157, 64604, 10176, 59397, 128416, 59397, 142922, 59397, 57859, 27910, 12653, 59397, 5703, 128252, 126198, 77703, 27910, 13325, 27910, 73771, 10176, 64604, 123920, 3159, 128332, 151645, 198, 151644, 77091, 198, 14558, 64604, 46586, 27910, 20931, 27910, 65398, 64604, 23364, 52704, 11798, 27910, 123961, 27910, 13325, 52704, 126259, 52704, 43982, 52704, 13325, 27910, 73771, 25871, 64604, 44330, 64604, 11071, 64604, 125463, 149, 235, 37524, 27910, 20931, 27910, 12653, 27910, 123829, 52704, 13325, 27910, 68785, 23364, 52704, 11798, 59397, 16157, 125352, 25, 124080, 27910, 73771, 16157, 59397, 14558, 64604, 43982, 27910, 11798, 59397, 59842, 27910, 21360, 52704, 73771, 123877, 27910, 10176, 59397, 12653, 27910, 47632, 52704, 37524, 27910, 31382, 91962, 52704, 20064, 27910, 98719, 27910, 25871, 52704, 85153, 52704, 8532, 27910, 14558, 59397, 16157, 52704, 10176, 59397, 128577, 56794, 52704, 69682, 27910, 11798, 27910, 73771, 16157, 64604, 10176, 59397, 77703, 27910, 13325, 59397, 128295, 59397, 14293, 27910, 16157, 27910, 12653, 59397, 5703, 85153, 52704, 8532, 27910, 55057, 23364, 125352, 77703, 27910, 13325, 27910, 73771, 10176, 64604, 123920, 23364, 52704, 11798, 59397, 63415, 27910, 23224, 59397, 10176, 27910, 31382, 149, 235, 68785, 37524, 27910, 69682, 27910, 11798, 27910, 73771, 16157, 64604, 56794, 125352, 73274, 27910, 11798, 59397, 21360, 27910, 81778, 52704, 14558, 124172, 27910, 43635, 59397, 23224, 64604, 56794, 52704, 69682, 27910, 29825, 27910, 13325, 149, 235, 27846, 52704, 31382, 33090, 27910, 11798, 27910, 73771, 25871, 52704, 63415, 27910, 12653, 52704, 124080, 27910, 73771, 35038, 52704, 128577, 45577, 27910, 91962, 52704, 11798, 27910, 73771, 125447, 27910, 8532, 52704, 31073, 27910, 23364, 52704, 11798, 59397, 63415, 27910, 35244, 59397, 41593, 52704, 73771, 74315, 27910, 41593, 27910, 123829, 52704, 41593, 52704, 128286, 52704, 39434, 27910, 23224, 27910, 31382, 27910, 55057, 13, 86941, 27910, 10176, 125352, 73274, 64604, 124035, 59397, 35244, 27910, 55334, 64604, 23364, 52704, 11798, 27910, 123961, 27910, 13325, 52704, 126259, 52704, 23364, 64604, 11071, 27910, 123862, 125352, 25871, 64604, 23364, 27910, 32790, 27910, 123862, 52704, 11071, 52704, 123877, 27910, 29825, 59397, 14558, 27910, 98719, 52704, 37524, 27910, 31382, 29825, 52704, 20931, 27910, 127877, 64604, 43982, 27910, 8532, 27910, 55057, 39434, 27910, 10176, 27910, 91344, 64604, 31073, 52704, 53479, 64604, 33090, 59397, 14293, 27910, 10176, 27910, 23224, 52704, 37524, 27910, 14293, 27910, 33090, 27910, 11798, 64604, 73771, 21360, 64604, 94957, 27910, 73771, 32790, 27910, 124210, 64604, 11798, 52704, 37524, 27910, 125962, 27910, 73771, 21360, 27910, 126789, 64604, 57859, 52704, 13, 151645, 198]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are an AI assistant specialized in understanding and explaining Islamic Hadith.\n",
            "You will be given a question related to a Hadith in Arabic.\n",
            "Your task is to answer the question clearly, concisely, and accurately based on Islamic scholarship.\n",
            "Respond in Arabic and follow the same tone and depth as classical Islamic explanations.<|im_end|>\n",
            "<|im_start|>user\n",
            "مَا هِيَ الرَّسَائِلُ الرَّئِيسِيَّةُ وَالدُّرُوسُ المُسْتَفَادَةُ والفَوَائِد المُستَخلصَة مِنَ الحَدِيثِ'لا تَسُبُّوا الأمْوَاتَ، فإنَّهُمْ قدْ أفْضَوْا إلى ما قَدَّمُوا.'؟<|im_end|>\n",
            "<|im_start|>assistant\n",
            "يُستَفَادُ مِنَ الحَدِيثِ عِدَّةُ دُرُوسٍ وَفَوَائِدَ، مِنْهَا: النَّهْيُ عَنْ سَبِّ الأَمْوَاتِ وَالإِسَاءَةِ إِلَيْهِمْ؛ لِأَنَّهُمْ قَدْ انْتَهَوْا إِلَى مَا قَدَّمُوا مِنْ أَعْمَالٍ، وَأَنَّهُ لَا يَنْبَغِي القَطْعُ لِأَحَدٍ بِالجَنَّةِ أَوِ النَّارِ؛ فَإِنَّ ذَلِكَ مِنْ أَخْصِّ خَصَائِصِ اللهِ تَعَالَى. كَمَا يُؤْخَذُ مِنَ الحَدِيثِ مُرَاعَاةُ مَشَاعِرِ الأَحْيَاءِ وَالحِفَاظُ عَلَى تَمَاسُكِ المُجْتَمَعِ وَتَجَنُّبُ التَّشَاحُنِ وَالتَّبَاغُضِ.<|im_end|>\n",
            "\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 14558, 64604, 46586, 27910, 20931, 27910, 65398, 64604, 23364, 52704, 11798, 27910, 123961, 27910, 13325, 52704, 126259, 52704, 43982, 52704, 13325, 27910, 73771, 25871, 64604, 44330, 64604, 11071, 64604, 125463, 149, 235, 37524, 27910, 20931, 27910, 12653, 27910, 123829, 52704, 13325, 27910, 68785, 23364, 52704, 11798, 59397, 16157, 125352, 25, 124080, 27910, 73771, 16157, 59397, 14558, 64604, 43982, 27910, 11798, 59397, 59842, 27910, 21360, 52704, 73771, 123877, 27910, 10176, 59397, 12653, 27910, 47632, 52704, 37524, 27910, 31382, 91962, 52704, 20064, 27910, 98719, 27910, 25871, 52704, 85153, 52704, 8532, 27910, 14558, 59397, 16157, 52704, 10176, 59397, 128577, 56794, 52704, 69682, 27910, 11798, 27910, 73771, 16157, 64604, 10176, 59397, 77703, 27910, 13325, 59397, 128295, 59397, 14293, 27910, 16157, 27910, 12653, 59397, 5703, 85153, 52704, 8532, 27910, 55057, 23364, 125352, 77703, 27910, 13325, 27910, 73771, 10176, 64604, 123920, 23364, 52704, 11798, 59397, 63415, 27910, 23224, 59397, 10176, 27910, 31382, 149, 235, 68785, 37524, 27910, 69682, 27910, 11798, 27910, 73771, 16157, 64604, 56794, 125352, 73274, 27910, 11798, 59397, 21360, 27910, 81778, 52704, 14558, 124172, 27910, 43635, 59397, 23224, 64604, 56794, 52704, 69682, 27910, 29825, 27910, 13325, 149, 235, 27846, 52704, 31382, 33090, 27910, 11798, 27910, 73771, 25871, 52704, 63415, 27910, 12653, 52704, 124080, 27910, 73771, 35038, 52704, 128577, 45577, 27910, 91962, 52704, 11798, 27910, 73771, 125447, 27910, 8532, 52704, 31073, 27910, 23364, 52704, 11798, 59397, 63415, 27910, 35244, 59397, 41593, 52704, 73771, 74315, 27910, 41593, 27910, 123829, 52704, 41593, 52704, 128286, 52704, 39434, 27910, 23224, 27910, 31382, 27910, 55057, 13, 86941, 27910, 10176, 125352, 73274, 64604, 124035, 59397, 35244, 27910, 55334, 64604, 23364, 52704, 11798, 27910, 123961, 27910, 13325, 52704, 126259, 52704, 23364, 64604, 11071, 27910, 123862, 125352, 25871, 64604, 23364, 27910, 32790, 27910, 123862, 52704, 11071, 52704, 123877, 27910, 29825, 59397, 14558, 27910, 98719, 52704, 37524, 27910, 31382, 29825, 52704, 20931, 27910, 127877, 64604, 43982, 27910, 8532, 27910, 55057, 39434, 27910, 10176, 27910, 91344, 64604, 31073, 52704, 53479, 64604, 33090, 59397, 14293, 27910, 10176, 27910, 23224, 52704, 37524, 27910, 14293, 27910, 33090, 27910, 11798, 64604, 73771, 21360, 64604, 94957, 27910, 73771, 32790, 27910, 124210, 64604, 11798, 52704, 37524, 27910, 125962, 27910, 73771, 21360, 27910, 126789, 64604, 57859, 52704, 13, 151645, 198]\n",
            "labels:\n",
            "يُستَفَادُ مِنَ الحَدِيثِ عِدَّةُ دُرُوسٍ وَفَوَائِدَ، مِنْهَا: النَّهْيُ عَنْ سَبِّ الأَمْوَاتِ وَالإِسَاءَةِ إِلَيْهِمْ؛ لِأَنَّهُمْ قَدْ انْتَهَوْا إِلَى مَا قَدَّمُوا مِنْ أَعْمَالٍ، وَأَنَّهُ لَا يَنْبَغِي القَطْعُ لِأَحَدٍ بِالجَنَّةِ أَوِ النَّارِ؛ فَإِنَّ ذَلِكَ مِنْ أَخْصِّ خَصَائِصِ اللهِ تَعَالَى. كَمَا يُؤْخَذُ مِنَ الحَدِيثِ مُرَاعَاةُ مَشَاعِرِ الأَحْيَاءِ وَالحِفَاظُ عَلَى تَمَاسُكِ المُجْتَمَعِ وَتَجَنُّبُ التَّشَاحُنِ وَالتَّبَاغُضِ.<|im_end|>\n",
            "\n",
            "Running tokenizer on dataset (num_proc=32): 100%|█| 6040/6040 [00:15<00:00, 401.\n",
            "eval example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 458, 15235, 17847, 27076, 304, 8660, 323, 25021, 15203, 23864, 410, 624, 2610, 686, 387, 2661, 264, 3405, 5435, 311, 264, 23864, 410, 304, 34117, 624, 7771, 3383, 374, 311, 4226, 279, 3405, 9355, 11, 3529, 285, 974, 11, 323, 29257, 3118, 389, 15203, 33125, 624, 65354, 304, 34117, 323, 1795, 279, 1852, 16232, 323, 7990, 438, 28824, 15203, 40841, 13, 151645, 198, 151644, 872, 198, 10176, 125352, 59842, 27910, 21360, 27910, 21360, 64604, 37524, 64604, 11071, 64604, 69423, 52704, 123961, 27910, 13325, 52704, 126259, 52704, 6, 20064, 64604, 124082, 52704, 8532, 27910, 53710, 27910, 20064, 72804, 64604, 124478, 27910, 73771, 16157, 52704, 92072, 27910, 8532, 27910, 73771, 55057, 128286, 64604, 128471, 37524, 123993, 27910, 73771, 10176, 27910, 68785, 126198, 73274, 27910, 8532, 59397, 21360, 27910, 20064, 64604, 53479, 64604, 29825, 59397, 11071, 52704, 10176, 64604, 23364, 52704, 11798, 27910, 124437, 52704, 73771, 14558, 27910, 70604, 52704, 128332, 45577, 27910, 124676, 27910, 25, 128259, 73274, 27910, 8532, 59397, 21360, 27910, 20064, 52704, 124172, 27910, 10176, 52704, 136666, 27910, 68785, 128827, 125352, 123894, 27910, 10176, 27910, 123829, 52704, 10176, 27910, 68785, 128827, 125352, 123913, 27910, 73771, 11071, 125352, 12653, 52704, 95198, 27910, 47632, 52704, 68785, 128827, 125352, 126249, 64604, 11071, 59397, 11798, 64604, 20064, 27910, 68785, 128827, 125352, 125069, 27910, 12653, 59397, 21360, 127837, 23364, 27910, 20064, 27910, 73771, 16157, 64604, 125555, 27910, 23224, 59397, 20931, 27910, 11071, 27910, 39423, 149, 234, 68785, 128827, 125352, 37524, 11071, 59397, 20064, 149, 234, 68785, 130915, 59397, 56794, 27910, 10176, 59397, 73274, 27910, 33090, 52704, 13325, 59397, 50243, 27910, 23224, 59397, 8532, 27910, 14558, 59397, 11798, 52704, 45577, 27910, 8532, 59397, 14558, 27910, 8532, 59397, 21360, 27910, 20064, 52704, 124147, 64604, 20931, 27910, 73771, 14558, 59397, 11798, 52704, 128827, 59397, 14558, 27910, 27490, 59397, 43635, 27910, 23224, 59397, 16157, 64604, 124009, 128522, 27910, 73771, 55057, 73274, 27910, 124655, 125352, 128962, 59397, 20931, 27910, 8532, 27910, 23364, 52704, 11798, 27910, 124326, 27910, 23224, 59397, 21360, 27910, 14558, 59397, 11798, 52704, 3159, 128332, 151645, 198, 151644, 77091, 198, 20064, 27910, 21360, 27910, 21360, 64604, 53710, 52704, 12653, 125352, 14558, 27910, 25871, 52704, 123961, 27910, 13325, 52704, 126259, 52704, 55891, 64604, 12653, 27910, 59842, 64604, 124035, 27910, 31382, 64604, 53710, 27910, 33090, 64604, 8532, 149, 235, 124080, 27910, 73771, 21360, 52704, 14558, 27910, 73771, 92072, 27910, 8532, 27910, 73771, 55057, 128286, 64604, 43982, 27910, 8532, 27910, 14558, 59397, 16157, 52704, 37524, 27910, 20064, 27910, 8532, 27910, 73771, 10176, 27910, 43982, 27910, 10176, 27910, 73771, 5703, 73274, 27910, 8532, 59397, 21360, 27910, 20064, 64604, 16157, 64604, 17166, 59397, 10176, 64604, 29825, 59397, 11071, 52704, 10176, 64604, 23364, 52704, 11798, 27910, 124437, 52704, 73771, 14558, 27910, 70604, 52704, 68785, 45577, 27910, 69682, 27910, 33090, 27910, 70604, 27910, 16157, 64604, 27846, 52704, 55334, 52704, 31073, 59397, 11071, 52704, 17166, 59397, 10176, 27910, 29825, 59397, 92381, 64604, 58656, 27910, 47632, 52704, 56794, 52704, 69682, 27910, 11798, 27910, 73771, 16157, 125352, 23364, 27910, 29825, 59397, 41593, 64604, 58656, 27910, 25871, 149, 234, 68785, 27846, 27910, 14558, 59397, 11798, 27910, 10176, 125352, 17166, 59397, 10176, 64604, 21360, 27910, 124210, 64604, 86941, 27910, 84532, 52704, 93543, 149, 234, 125040, 27910, 14558, 59397, 11071, 64604, 23364, 27910, 29825, 59397, 41593, 64604, 58656, 149, 235, 68785, 37524, 27910, 39697, 27910, 65398, 27910, 124080, 27910, 73771, 21360, 52704, 14558, 64604, 73771, 92072, 27910, 8532, 27910, 73771, 55057, 128286, 64604, 43982, 27910, 8532, 27910, 14558, 59397, 16157, 52704, 37524, 27910, 20064, 27910, 8532, 27910, 73771, 10176, 27910, 45577, 52704, 14558, 17166, 59397, 91962, 52704, 33090, 27910, 70604, 27910, 25871, 52704, 27846, 52704, 55334, 52704, 31073, 59397, 11071, 52704, 63415, 27910, 29825, 59397, 31073, 27910, 49388, 149, 235, 63415, 64604, 35244, 59397, 11071, 27910, 55057, 56794, 52704, 91962, 52704, 14293, 59397, 10176, 27910, 49388, 52704, 17166, 59397, 20931, 27910, 123829, 52704, 13325, 27910, 25871, 52704, 13, 151645, 198]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are an AI assistant specialized in understanding and explaining Islamic Hadith.\n",
            "You will be given a question related to a Hadith in Arabic.\n",
            "Your task is to answer the question clearly, concisely, and accurately based on Islamic scholarship.\n",
            "Respond in Arabic and follow the same tone and depth as classical Islamic explanations.<|im_end|>\n",
            "<|im_start|>user\n",
            "مَا سَبَبُ وُرُودِ الحَدِيثِ'سُئِلَ رَسولُ اللَّهِ صَلَّى اللهُ عليه وسلَّمَ، ما يَلْبَسُ المُحْرِمُ مِنَ الثِّيَابِ؟ فَقالَ: لا يَلْبَسِ القَمِيصَ، ولَا العَمَائِمَ، ولَا السَّرَاوِيلَاتِ، ولَا البُرْنُسَ، ولَا ثَوْبًا مَسَّهُ زَعْفَرَانٌ، ولَا ورْسٌ، وإنْ لَمْ يَجِدْ نَعْلَيْنِ فَلْيَلْبَسِ الخُفَّيْنِ ولْيَقْطَعْهُما حتَّى يَكونَا أسْفَلَ مِنَ الكَعْبَيْنِ.'؟<|im_end|>\n",
            "<|im_start|>assistant\n",
            "سَبَبُ رِوَايَةِ الحَدِيثِ هُوَ سُؤَالُ رَجُلٍ النَّبِيَّ صَلَّى اللهُ عَلَيْهِ وَسَلَّمَ عَمَّا يَلْبَسُهُ الْمُحْرِمُ مِنَ الثِّيَابِ، فَأَجَابَهُ بِذِكْرِ الْمَحْظُورَاتِ لِأَنَّهَا مَحْصُورَةٌ، بَيْنَمَا الْمُبَاحُ كَثِيرٌ غَيْرُ مَحْصُورٍ، وَزَادَ النَّبِيُّ صَلَّى اللهُ عَلَيْهِ وَسَلَّمَ فِي الْإِجَابَةِ بِذِكْرِ أَحْكَامٍ أُخْرَى لِإِتْمَامِ الْفَائِدَةِ.<|im_end|>\n",
            "\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 20064, 27910, 21360, 27910, 21360, 64604, 53710, 52704, 12653, 125352, 14558, 27910, 25871, 52704, 123961, 27910, 13325, 52704, 126259, 52704, 55891, 64604, 12653, 27910, 59842, 64604, 124035, 27910, 31382, 64604, 53710, 27910, 33090, 64604, 8532, 149, 235, 124080, 27910, 73771, 21360, 52704, 14558, 27910, 73771, 92072, 27910, 8532, 27910, 73771, 55057, 128286, 64604, 43982, 27910, 8532, 27910, 14558, 59397, 16157, 52704, 37524, 27910, 20064, 27910, 8532, 27910, 73771, 10176, 27910, 43982, 27910, 10176, 27910, 73771, 5703, 73274, 27910, 8532, 59397, 21360, 27910, 20064, 64604, 16157, 64604, 17166, 59397, 10176, 64604, 29825, 59397, 11071, 52704, 10176, 64604, 23364, 52704, 11798, 27910, 124437, 52704, 73771, 14558, 27910, 70604, 52704, 68785, 45577, 27910, 69682, 27910, 33090, 27910, 70604, 27910, 16157, 64604, 27846, 52704, 55334, 52704, 31073, 59397, 11071, 52704, 17166, 59397, 10176, 27910, 29825, 59397, 92381, 64604, 58656, 27910, 47632, 52704, 56794, 52704, 69682, 27910, 11798, 27910, 73771, 16157, 125352, 23364, 27910, 29825, 59397, 41593, 64604, 58656, 27910, 25871, 149, 234, 68785, 27846, 27910, 14558, 59397, 11798, 27910, 10176, 125352, 17166, 59397, 10176, 64604, 21360, 27910, 124210, 64604, 86941, 27910, 84532, 52704, 93543, 149, 234, 125040, 27910, 14558, 59397, 11071, 64604, 23364, 27910, 29825, 59397, 41593, 64604, 58656, 149, 235, 68785, 37524, 27910, 39697, 27910, 65398, 27910, 124080, 27910, 73771, 21360, 52704, 14558, 64604, 73771, 92072, 27910, 8532, 27910, 73771, 55057, 128286, 64604, 43982, 27910, 8532, 27910, 14558, 59397, 16157, 52704, 37524, 27910, 20064, 27910, 8532, 27910, 73771, 10176, 27910, 45577, 52704, 14558, 17166, 59397, 91962, 52704, 33090, 27910, 70604, 27910, 25871, 52704, 27846, 52704, 55334, 52704, 31073, 59397, 11071, 52704, 63415, 27910, 29825, 59397, 31073, 27910, 49388, 149, 235, 63415, 64604, 35244, 59397, 11071, 27910, 55057, 56794, 52704, 91962, 52704, 14293, 59397, 10176, 27910, 49388, 52704, 17166, 59397, 20931, 27910, 123829, 52704, 13325, 27910, 25871, 52704, 13, 151645, 198]\n",
            "labels:\n",
            "سَبَبُ رِوَايَةِ الحَدِيثِ هُوَ سُؤَالُ رَجُلٍ النَّبِيَّ صَلَّى اللهُ عَلَيْهِ وَسَلَّمَ عَمَّا يَلْبَسُهُ الْمُحْرِمُ مِنَ الثِّيَابِ، فَأَجَابَهُ بِذِكْرِ الْمَحْظُورَاتِ لِأَنَّهَا مَحْصُورَةٌ، بَيْنَمَا الْمُبَاحُ كَثِيرٌ غَيْرُ مَحْصُورٍ، وَزَادَ النَّبِيُّ صَلَّى اللهُ عَلَيْهِ وَسَلَّمَ فِي الْإِجَابَةِ بِذِكْرِ أَحْكَامٍ أُخْرَى لِإِتْمَامِ الْفَائِدَةِ.<|im_end|>\n",
            "\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 17:46:13,633 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 17:46:13,635 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|2025-05-16 17:46:13] llamafactory.model.model_utils.kv_cache:143 >> KV cache is disabled during training.\n",
            "model.safetensors: 100%|████████████████████| 1.50G/1.50G [00:07<00:00, 198MB/s]\n",
            "[INFO|modeling_utils.py:1124] 2025-05-16 17:46:22,476 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/model.safetensors\n",
            "[INFO|modeling_utils.py:2167] 2025-05-16 17:46:22,478 >> Instantiating Qwen3ForCausalLM model under default dtype torch.bfloat16.\n",
            "[INFO|configuration_utils.py:1142] 2025-05-16 17:46:22,481 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:4930] 2025-05-16 17:46:23,204 >> All model checkpoint weights were used when initializing Qwen3ForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4938] 2025-05-16 17:46:23,205 >> All the weights of Qwen3ForCausalLM were initialized from the model checkpoint at Qwen/Qwen3-0.6B.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen3ForCausalLM for predictions without further training.\n",
            "generation_config.json: 100%|██████████████████| 239/239 [00:00<00:00, 1.64MB/s]\n",
            "[INFO|configuration_utils.py:1097] 2025-05-16 17:46:23,725 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/generation_config.json\n",
            "[INFO|configuration_utils.py:1142] 2025-05-16 17:46:23,725 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"temperature\": 0.6,\n",
            "  \"top_k\": 20,\n",
            "  \"top_p\": 0.95\n",
            "}\n",
            "\n",
            "[INFO|2025-05-16 17:46:23] llamafactory.model.model_utils.checkpointing:143 >> Gradient checkpointing enabled.\n",
            "[INFO|2025-05-16 17:46:23] llamafactory.model.model_utils.attention:143 >> Using torch SDPA for faster training and inference.\n",
            "[INFO|2025-05-16 17:46:23] llamafactory.model.adapter:143 >> Upcasting trainable params to float32.\n",
            "[INFO|2025-05-16 17:46:23] llamafactory.model.adapter:143 >> Fine-tuning method: LoRA\n",
            "[INFO|2025-05-16 17:46:23] llamafactory.model.model_utils.misc:143 >> Found linear modules: o_proj,down_proj,q_proj,k_proj,v_proj,gate_proj,up_proj\n",
            "[INFO|2025-05-16 17:46:24] llamafactory.model.loader:143 >> trainable params: 40,370,176 || all params: 636,420,096 || trainable%: 6.3433\n",
            "[INFO|trainer.py:748] 2025-05-16 17:46:24,802 >> Using auto half precision backend\n",
            "[WARNING|2025-05-16 17:46:24] llamafactory.train.callbacks:154 >> Previous trainer log in this folder will be deleted.\n",
            "[INFO|trainer.py:2813] 2025-05-16 17:46:24,805 >> Loading model from /kaggle/working/Models_Ouput2/last-checkpoint.\n",
            "[INFO|trainer.py:2414] 2025-05-16 17:46:26,683 >> ***** Running training *****\n",
            "[INFO|trainer.py:2415] 2025-05-16 17:46:26,684 >>   Num examples = 24,160\n",
            "[INFO|trainer.py:2416] 2025-05-16 17:46:26,684 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2417] 2025-05-16 17:46:26,684 >>   Instantaneous batch size per device = 1\n",
            "[INFO|trainer.py:2420] 2025-05-16 17:46:26,684 >>   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "[INFO|trainer.py:2421] 2025-05-16 17:46:26,684 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:2422] 2025-05-16 17:46:26,684 >>   Total optimization steps = 18,120\n",
            "[INFO|trainer.py:2423] 2025-05-16 17:46:26,688 >>   Number of trainable parameters = 40,370,176\n",
            "[WARNING|logging.py:328] 2025-05-16 17:46:26,689 >> Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n",
            "\tsave_steps: 500 (from args) != 100 (from trainer_state.json)\n",
            "[INFO|trainer.py:2445] 2025-05-16 17:46:26,689 >>   Continuing training from checkpoint, will skip to saved global_step\n",
            "[INFO|trainer.py:2446] 2025-05-16 17:46:26,689 >>   Continuing training from epoch 2\n",
            "[INFO|trainer.py:2447] 2025-05-16 17:46:26,689 >>   Continuing training from global step 12500\n",
            "[INFO|trainer.py:2449] 2025-05-16 17:46:26,689 >>   Will skip the first 2 epochs then the first 1680 batches in the first epoch.\n",
            "[INFO|integration_utils.py:831] 2025-05-16 17:46:26,693 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myoussefkhalafabdullatif\u001b[0m (\u001b[33myoussefkhalafabdullatif-kafr-el-sheikh-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/LLaMA-Factory/wandb/run-20250516_174627-cmr8tv0u\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mQwennn\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/youssefkhalafabdullatif-kafr-el-sheikh-university/llamafactory\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/youssefkhalafabdullatif-kafr-el-sheikh-university/llamafactory/runs/cmr8tv0u\u001b[0m\n",
            "{'loss': 0.284, 'grad_norm': 1.0280028581619263, 'learning_rate': 2.613444400848287e-05, 'epoch': 2.08}\n",
            "{'loss': 0.2852, 'grad_norm': 1.2673025131225586, 'learning_rate': 2.571235652160091e-05, 'epoch': 2.09}\n",
            " 70%|████████████████████████▎          | 12600/18120 [06:12<5:17:05,  3.45s/it][INFO|trainer.py:3984] 2025-05-16 17:52:40,769 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-12600\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 17:52:41,580 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 17:52:41,581 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 17:52:41,926 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-12600/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 17:52:41,926 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-12600/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 17:52:42,867 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 17:52:42,868 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2893, 'grad_norm': 1.076798915863037, 'learning_rate': 2.529252234174041e-05, 'epoch': 2.09}\n",
            "{'loss': 0.2837, 'grad_norm': 0.7327485084533691, 'learning_rate': 2.4874980419378647e-05, 'epoch': 2.1}\n",
            " 70%|████████████████████████▌          | 12700/18120 [12:52<5:54:34,  3.93s/it][INFO|trainer.py:3984] 2025-05-16 17:59:20,603 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-12700\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 17:59:21,055 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 17:59:21,056 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 17:59:21,399 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-12700/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 17:59:21,400 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-12700/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 17:59:22,382 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 17:59:22,383 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2859, 'grad_norm': 1.2723850011825562, 'learning_rate': 2.445976949232676e-05, 'epoch': 2.11}\n",
            "{'loss': 0.2841, 'grad_norm': 1.1690808534622192, 'learning_rate': 2.4046928082135733e-05, 'epoch': 2.12}\n",
            " 71%|████████████████████████▋          | 12800/18120 [19:17<5:45:14,  3.89s/it][INFO|trainer.py:3984] 2025-05-16 18:05:45,917 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-12800\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 18:05:46,362 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 18:05:46,363 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:05:46,698 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-12800/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:05:46,698 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-12800/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:05:47,718 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:05:47,719 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2772, 'grad_norm': 1.2063932418823242, 'learning_rate': 2.3636494490522624e-05, 'epoch': 2.13}\n",
            "{'loss': 0.2829, 'grad_norm': 1.2601985931396484, 'learning_rate': 2.3228506795817072e-05, 'epoch': 2.14}\n",
            " 71%|████████████████████████▉          | 12900/18120 [25:41<5:48:14,  4.00s/it][INFO|trainer.py:3984] 2025-05-16 18:12:09,841 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-12900\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 18:12:10,314 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 18:12:10,315 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:12:10,688 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-12900/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:12:10,688 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-12900/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:12:11,687 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:12:11,688 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.293, 'grad_norm': 1.1223324537277222, 'learning_rate': 2.282300284942846e-05, 'epoch': 2.14}\n",
            "{'loss': 0.2946, 'grad_norm': 1.2425414323806763, 'learning_rate': 2.2420020272334337e-05, 'epoch': 2.15}\n",
            " 72%|█████████████████████████          | 13000/18120 [32:26<5:06:36,  3.59s/it][INFO|trainer.py:3984] 2025-05-16 18:18:54,669 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-13000\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 18:18:55,878 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 18:18:55,880 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:18:56,221 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-13000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:18:56,221 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-13000/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:18:57,204 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:18:57,204 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2888, 'grad_norm': 1.176163673400879, 'learning_rate': 2.2019596451590047e-05, 'epoch': 2.16}\n",
            "{'loss': 0.2921, 'grad_norm': 1.073018193244934, 'learning_rate': 2.162176853686006e-05, 'epoch': 2.17}\n",
            " 72%|█████████████████████████▎         | 13100/18120 [38:33<5:24:58,  3.88s/it][INFO|trainer.py:3984] 2025-05-16 18:25:01,352 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-13100\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 18:25:01,852 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 18:25:01,853 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:25:02,196 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-13100/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:25:02,196 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-13100/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:25:03,183 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:25:03,184 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.3014, 'grad_norm': 1.3194624185562134, 'learning_rate': 2.1226573436971487e-05, 'epoch': 2.18}\n",
            "{'loss': 0.2828, 'grad_norm': 1.3240703344345093, 'learning_rate': 2.0834047816489772e-05, 'epoch': 2.19}\n",
            " 73%|█████████████████████████▍         | 13200/18120 [44:55<4:34:18,  3.35s/it][INFO|trainer.py:3984] 2025-05-16 18:31:24,118 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-13200\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 18:31:24,572 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 18:31:24,573 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:31:24,907 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-13200/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:31:24,908 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-13200/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:31:25,881 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:31:25,882 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2946, 'grad_norm': 1.529966950416565, 'learning_rate': 2.0444228092317057e-05, 'epoch': 2.19}\n",
            "{'loss': 0.2905, 'grad_norm': 1.0397886037826538, 'learning_rate': 2.005715043031369e-05, 'epoch': 2.2}\n",
            " 73%|█████████████████████████▋         | 13300/18120 [51:20<7:07:33,  5.32s/it][INFO|trainer.py:3984] 2025-05-16 18:37:48,674 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-13300\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 18:37:49,190 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 18:37:49,191 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:37:49,531 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-13300/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:37:49,532 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-13300/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:37:50,518 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:37:50,519 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2847, 'grad_norm': 0.8956925868988037, 'learning_rate': 1.967285074194283e-05, 'epoch': 2.21}\n",
            "{'loss': 0.2709, 'grad_norm': 1.2051565647125244, 'learning_rate': 1.9291364680938688e-05, 'epoch': 2.22}\n",
            " 74%|█████████████████████████▉         | 13400/18120 [57:53<5:10:19,  3.94s/it][INFO|trainer.py:3984] 2025-05-16 18:44:21,527 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-13400\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 18:44:21,977 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 18:44:21,978 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:44:22,319 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-13400/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:44:22,319 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-13400/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:44:23,320 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:44:23,321 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2754, 'grad_norm': 1.2182625532150269, 'learning_rate': 1.891272763999884e-05, 'epoch': 2.23}\n",
            "{'loss': 0.278, 'grad_norm': 1.2709006071090698, 'learning_rate': 1.8536974747500556e-05, 'epoch': 2.24}\n",
            " 75%|████████████████████████▌        | 13500/18120 [1:04:22<4:29:30,  3.50s/it][INFO|trainer.py:3984] 2025-05-16 18:50:50,768 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-13500\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 18:50:51,930 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 18:50:51,931 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:50:52,278 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-13500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:50:52,279 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-13500/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:50:53,292 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:50:53,293 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2863, 'grad_norm': 1.142155647277832, 'learning_rate': 1.8164140864241723e-05, 'epoch': 2.24}\n",
            "{'loss': 0.282, 'grad_norm': 1.218385100364685, 'learning_rate': 1.7794260580206673e-05, 'epoch': 2.25}\n",
            " 75%|████████████████████████▊        | 13600/18120 [1:10:41<4:50:07,  3.85s/it][INFO|trainer.py:3984] 2025-05-16 18:57:10,041 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-13600\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 18:57:11,199 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 18:57:11,201 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:57:11,533 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-13600/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:57:11,534 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-13600/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 18:57:12,497 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 18:57:12,498 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2756, 'grad_norm': 0.6981252431869507, 'learning_rate': 1.742736821135702e-05, 'epoch': 2.26}\n",
            "{'loss': 0.2711, 'grad_norm': 1.193818211555481, 'learning_rate': 1.7063497796447935e-05, 'epoch': 2.27}\n",
            " 76%|████████████████████████▉        | 13700/18120 [1:17:00<5:04:13,  4.13s/it][INFO|trainer.py:3984] 2025-05-16 19:03:29,152 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-13700\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 19:03:29,619 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 19:03:29,621 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:03:29,952 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-13700/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:03:29,953 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-13700/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:03:30,940 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:03:30,941 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2723, 'grad_norm': 1.1021385192871094, 'learning_rate': 1.670268309387029e-05, 'epoch': 2.28}\n",
            "{'loss': 0.2821, 'grad_norm': 1.4959111213684082, 'learning_rate': 1.634495757851855e-05, 'epoch': 2.28}\n",
            " 76%|█████████████████████████▏       | 13800/18120 [1:23:36<4:09:16,  3.46s/it][INFO|trainer.py:3984] 2025-05-16 19:10:05,082 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-13800\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 19:10:05,612 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 19:10:05,614 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:10:05,963 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-13800/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:10:05,964 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-13800/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:10:06,922 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:10:06,923 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2701, 'grad_norm': 1.3577196598052979, 'learning_rate': 1.599035443868518e-05, 'epoch': 2.29}\n",
            "{'loss': 0.2809, 'grad_norm': 1.391587495803833, 'learning_rate': 1.5638906572981604e-05, 'epoch': 2.3}\n",
            " 77%|█████████████████████████▎       | 13900/18120 [1:30:00<4:57:41,  4.23s/it][INFO|trainer.py:3984] 2025-05-16 19:16:29,077 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-13900\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 19:16:29,938 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 19:16:29,939 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:16:30,270 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-13900/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:16:30,271 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-13900/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:16:31,270 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:16:31,270 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2847, 'grad_norm': 1.1502324342727661, 'learning_rate': 1.529064658728598e-05, 'epoch': 2.31}\n",
            "{'loss': 0.2772, 'grad_norm': 1.315737009048462, 'learning_rate': 1.4945606791718092e-05, 'epoch': 2.32}\n",
            " 77%|█████████████████████████▍       | 14000/18120 [1:36:40<4:16:22,  3.73s/it][INFO|trainer.py:3984] 2025-05-16 19:23:08,491 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-14000\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 19:23:09,306 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 19:23:09,307 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:23:09,649 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-14000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:23:09,650 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-14000/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:23:10,624 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:23:10,625 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2798, 'grad_norm': 1.5041948556900024, 'learning_rate': 1.4603819197641883e-05, 'epoch': 2.33}\n",
            "{'loss': 0.2712, 'grad_norm': 1.1226636171340942, 'learning_rate': 1.4265315514695488e-05, 'epoch': 2.33}\n",
            " 78%|█████████████████████████▋       | 14100/18120 [1:43:08<4:30:23,  4.04s/it][INFO|trainer.py:3984] 2025-05-16 19:29:37,160 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-14100\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 19:29:37,603 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 19:29:37,604 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:29:37,950 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-14100/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:29:37,950 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-14100/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:29:38,894 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:29:38,895 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2805, 'grad_norm': 0.982099175453186, 'learning_rate': 1.3930127147849314e-05, 'epoch': 2.34}\n",
            "{'loss': 0.2882, 'grad_norm': 1.165469765663147, 'learning_rate': 1.3598285194492521e-05, 'epoch': 2.35}\n",
            " 78%|█████████████████████████▊       | 14200/18120 [1:49:38<3:45:29,  3.45s/it][INFO|trainer.py:3984] 2025-05-16 19:36:06,942 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-14200\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 19:36:08,084 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 19:36:08,085 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:36:08,423 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-14200/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:36:08,423 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-14200/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:36:09,397 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:36:09,398 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2837, 'grad_norm': 1.305770754814148, 'learning_rate': 1.326982044154787e-05, 'epoch': 2.36}\n",
            "{'loss': 0.2742, 'grad_norm': 1.5525685548782349, 'learning_rate': 1.2944763362615413e-05, 'epoch': 2.37}\n",
            " 79%|██████████████████████████       | 14300/18120 [1:56:20<4:33:20,  4.29s/it][INFO|trainer.py:3984] 2025-05-16 19:42:48,943 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-14300\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 19:42:49,391 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 19:42:49,392 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:42:49,727 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-14300/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:42:49,728 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-14300/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:42:50,698 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:42:50,699 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2698, 'grad_norm': 1.0929417610168457, 'learning_rate': 1.2623144115145342e-05, 'epoch': 2.38}\n",
            "{'loss': 0.2764, 'grad_norm': 1.1220225095748901, 'learning_rate': 1.2304992537640092e-05, 'epoch': 2.38}\n",
            " 79%|██████████████████████████▏      | 14400/18120 [2:02:45<3:56:09,  3.81s/it][INFO|trainer.py:3984] 2025-05-16 19:49:13,956 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-14400\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 19:49:14,410 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 19:49:14,411 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:49:14,742 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-14400/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:49:14,743 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-14400/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:49:15,737 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:49:15,738 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2729, 'grad_norm': 1.229873776435852, 'learning_rate': 1.1990338146885977e-05, 'epoch': 2.39}\n",
            "{'loss': 0.2764, 'grad_norm': 1.4030100107192993, 'learning_rate': 1.1679210135214858e-05, 'epoch': 2.4}\n",
            " 80%|██████████████████████████▍      | 14500/18120 [2:09:03<3:36:01,  3.58s/it][INFO|trainer.py:3984] 2025-05-16 19:55:31,866 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-14500\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 19:55:32,343 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 19:55:32,344 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:55:32,679 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-14500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:55:32,680 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-14500/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 19:55:33,671 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 19:55:33,672 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2718, 'grad_norm': 1.1974605321884155, 'learning_rate': 1.1371637367795735e-05, 'epoch': 2.41}\n",
            "{'loss': 0.288, 'grad_norm': 1.3544508218765259, 'learning_rate': 1.1067648379956714e-05, 'epoch': 2.42}\n",
            " 81%|██████████████████████████▌      | 14600/18120 [2:15:18<3:30:49,  3.59s/it][INFO|trainer.py:3984] 2025-05-16 20:01:47,000 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-14600\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 20:01:47,784 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 20:01:47,785 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:01:48,132 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-14600/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:01:48,133 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-14600/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:01:49,148 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:01:49,149 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.27, 'grad_norm': 1.3159441947937012, 'learning_rate': 1.0767271374537724e-05, 'epoch': 2.43}\n",
            "{'loss': 0.2764, 'grad_norm': 1.531108021736145, 'learning_rate': 1.0470534219273903e-05, 'epoch': 2.43}\n",
            " 81%|██████████████████████████▊      | 14700/18120 [2:22:05<3:23:12,  3.57s/it][INFO|trainer.py:3984] 2025-05-16 20:08:34,016 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-14700\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 20:08:35,150 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 20:08:35,151 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:08:35,496 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-14700/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:08:35,497 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-14700/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:08:36,513 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:08:36,514 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2685, 'grad_norm': 1.3860596418380737, 'learning_rate': 1.0177464444210133e-05, 'epoch': 2.44}\n",
            "{'loss': 0.2882, 'grad_norm': 1.0219587087631226, 'learning_rate': 9.888089239146963e-06, 'epoch': 2.45}\n",
            " 82%|██████████████████████████▉      | 14800/18120 [2:28:24<3:33:20,  3.86s/it][INFO|trainer.py:3984] 2025-05-16 20:14:53,199 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-14800\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 20:14:54,009 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 20:14:54,010 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:14:54,348 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-14800/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:14:54,349 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-14800/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:14:55,356 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:14:55,357 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.288, 'grad_norm': 1.3057914972305298, 'learning_rate': 9.602435451118047e-06, 'epoch': 2.46}\n",
            "{'loss': 0.2797, 'grad_norm': 1.2784461975097656, 'learning_rate': 9.320529581899335e-06, 'epoch': 2.47}\n",
            " 82%|███████████████████████████▏     | 14900/18120 [2:34:32<3:26:08,  3.84s/it][INFO|trainer.py:3984] 2025-05-16 20:21:01,008 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-14900\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 20:21:02,142 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 20:21:02,144 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:21:02,481 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-14900/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:21:02,482 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-14900/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:21:03,484 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:21:03,485 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2812, 'grad_norm': 1.4044731855392456, 'learning_rate': 9.042397785550405e-06, 'epoch': 2.48}\n",
            "{'loss': 0.2719, 'grad_norm': 1.240498661994934, 'learning_rate': 8.768065865987995e-06, 'epoch': 2.48}\n",
            " 83%|███████████████████████████▎     | 15000/18120 [2:41:26<3:16:49,  3.79s/it][INFO|trainer.py:3984] 2025-05-16 20:27:54,665 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-15000\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 20:27:55,213 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 20:27:55,215 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:27:55,569 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-15000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:27:55,569 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-15000/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:27:56,551 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:27:56,551 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2862, 'grad_norm': 1.1060854196548462, 'learning_rate': 8.49755927459196e-06, 'epoch': 2.49}\n",
            "{'loss': 0.2622, 'grad_norm': 1.4075932502746582, 'learning_rate': 8.230903107844078e-06, 'epoch': 2.5}\n",
            " 83%|███████████████████████████▌     | 15100/18120 [2:47:54<3:27:08,  4.12s/it][INFO|trainer.py:3984] 2025-05-16 20:34:22,467 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-15100\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 20:34:23,511 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 20:34:23,512 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:34:23,846 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-15100/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:34:23,847 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-15100/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:34:24,825 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:34:24,825 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2735, 'grad_norm': 1.277173399925232, 'learning_rate': 7.968122104999676e-06, 'epoch': 2.51}\n",
            "{'loss': 0.2857, 'grad_norm': 1.4734828472137451, 'learning_rate': 7.70924064579236e-06, 'epoch': 2.52}\n",
            " 84%|███████████████████████████▋     | 15200/18120 [2:54:10<2:53:16,  3.56s/it][INFO|trainer.py:3984] 2025-05-16 20:40:39,080 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-15200\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 20:40:39,522 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 20:40:39,524 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:40:39,858 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-15200/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:40:39,859 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-15200/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:40:40,833 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:40:40,834 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2647, 'grad_norm': 1.183908224105835, 'learning_rate': 7.454282748172281e-06, 'epoch': 2.52}\n",
            "{'loss': 0.272, 'grad_norm': 1.2471554279327393, 'learning_rate': 7.2032720660777706e-06, 'epoch': 2.53}\n",
            " 84%|███████████████████████████▊     | 15300/18120 [3:00:38<2:39:35,  3.40s/it][INFO|trainer.py:3984] 2025-05-16 20:47:07,065 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-15300\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 20:47:07,550 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 20:47:07,551 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:47:07,883 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-15300/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:47:07,884 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-15300/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:47:08,877 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:47:08,877 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2815, 'grad_norm': 1.2211905717849731, 'learning_rate': 6.95623188724081e-06, 'epoch': 2.54}\n",
            "{'loss': 0.2808, 'grad_norm': 1.453582525253296, 'learning_rate': 6.713185131026567e-06, 'epoch': 2.55}\n",
            " 85%|████████████████████████████     | 15400/18120 [3:06:47<2:45:13,  3.64s/it][INFO|trainer.py:3984] 2025-05-16 20:53:16,068 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-15400\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 20:53:16,890 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 20:53:16,892 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:53:17,245 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-15400/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:53:17,245 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-15400/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:53:18,228 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:53:18,229 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2719, 'grad_norm': 1.27803635597229, 'learning_rate': 6.474154346306999e-06, 'epoch': 2.56}\n",
            "{'loss': 0.2743, 'grad_norm': 1.2783340215682983, 'learning_rate': 6.239161709368774e-06, 'epoch': 2.57}\n",
            " 86%|████████████████████████████▏    | 15500/18120 [3:13:20<3:03:29,  4.20s/it][INFO|trainer.py:3984] 2025-05-16 20:59:49,160 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-15500\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 20:59:49,955 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 20:59:49,956 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:59:50,298 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-15500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:59:50,299 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-15500/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 20:59:51,254 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 20:59:51,254 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2817, 'grad_norm': 1.371692180633545, 'learning_rate': 6.00822902185601e-06, 'epoch': 2.57}\n",
            "{'loss': 0.2665, 'grad_norm': 1.6115282773971558, 'learning_rate': 5.781377708747493e-06, 'epoch': 2.58}\n",
            " 86%|████████████████████████████▍    | 15600/18120 [3:19:39<2:36:29,  3.73s/it][INFO|trainer.py:3984] 2025-05-16 21:06:07,515 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-15600\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 21:06:07,965 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 21:06:07,967 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 21:06:08,309 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-15600/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 21:06:08,309 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-15600/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 21:06:09,306 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 21:06:09,306 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            "{'loss': 0.2767, 'grad_norm': 1.3451199531555176, 'learning_rate': 5.558628816368972e-06, 'epoch': 2.59}\n",
            "{'loss': 0.2721, 'grad_norm': 1.2596265077590942, 'learning_rate': 5.340003010440603e-06, 'epoch': 2.6}\n",
            " 87%|████████████████████████████▌    | 15700/18120 [3:25:49<2:23:12,  3.55s/it][INFO|trainer.py:3984] 2025-05-16 21:12:18,222 >> Saving model checkpoint to /kaggle/working/Models_Ouput2/checkpoint-15700\n",
            "[INFO|configuration_utils.py:693] 2025-05-16 21:12:21,999 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen3-0.6B/snapshots/6130ef31402718485ca4d80a6234f70d9a4cf362/config.json\n",
            "[INFO|configuration_utils.py:765] 2025-05-16 21:12:22,001 >> Model config Qwen3Config {\n",
            "  \"architectures\": [\n",
            "    \"Qwen3ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_bias\": false,\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"head_dim\": 128,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1024,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"max_position_embeddings\": 40960,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen3\",\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 8,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.51.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 21:12:22,338 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/checkpoint-15700/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 21:12:22,339 >> Special tokens file saved in /kaggle/working/Models_Ouput2/checkpoint-15700/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:2510] 2025-05-16 21:12:23,377 >> tokenizer config file saved in /kaggle/working/Models_Ouput2/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2519] 2025-05-16 21:12:23,378 >> Special tokens file saved in /kaggle/working/Models_Ouput2/special_tokens_map.json\n",
            " 87%|████████████████████████████▌    | 15715/18120 [3:26:49<2:36:14,  3.90s/it]"
          ]
        }
      ],
      "source": [
        "!cd LLaMA-Factory/ && llamafactory-cli train /kaggle/working/LLaMA-Factory/examples/train_lora/QA.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkfICVX-aQpk"
      },
      "source": [
        "# Evaluate After Fine tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708,
          "referenced_widgets": [
            "3168cf8f28c847eab14efef90653094a",
            "3ee93bfe50474b9180fdec8406e7c54f",
            "8928a77a1b584e4db7586e38859c2739",
            "2f0ec1b42e4e46c6b018bb71fd92e9a4",
            "48f3725fc243472586bbfc9a061db32d",
            "6064bda9cefb4567abd50d8b8b5c1dc3",
            "cea925fe80bc4d26b1f89f6ca44ad764",
            "395f0fd2b7644d728016146af81d7682",
            "723ee12bd10a4391aca27c36a90a2ec7",
            "f70fc35377d049a39ae95af415d74a84",
            "d82d7baa005f41aab07e4132b3e496f4",
            "0803f9e6c2604059b266b62f22654d03",
            "27d64f4ec9bf4613a8d86bb4f5bab3a4",
            "069b332562544db5bed4b792110e13c6",
            "7ed4f8b20b4c4390af731f5b1417165c",
            "97538235fa3b4b7d974cb991f09b5427",
            "a17c84a585e84d90a0cdc3a0a9bebc0c",
            "30813041b1ef4df698fb7d7108110764",
            "6cbf3d723ada4fba8a44308d149d1402",
            "df5c778bbff0496cb3841ea2c8d83bc7",
            "fa4b3761bf3b4bd7ae9fc40bd3f09316",
            "529ff264df854d058e67532e60f1a2aa",
            "72baeb12126a4cad99928c92ebb8bee6",
            "8a6c3804417b49e4b35ee3083a10fac9",
            "a1b51e474553440db9a8cefefd9e1f97",
            "f160162556e5428982f0e9a069335d37",
            "68cebe69ad8046f28c770350dc23f7f7",
            "9728c598fe444ce78b14c9af23b7df77",
            "1d5693e0ee2144448feee08ebbc8d02c",
            "421be503e61e46389d4e345983257a43",
            "88abb58611774c068e1f3632f0f97879",
            "b9c51f26f8a24c28957afd7bca9c6fd7",
            "7baa9226ead74c18a2dca0f5da58a31b",
            "7bd1d132b760432692d67b9b465cb8ba",
            "12fd063b2fe64b979380efcca758e8c6",
            "72595e3fb5a744fba818852f6802c02d",
            "c3cbd1237aef458980d6b1c6d703e99d",
            "309fef4258f445cc98245f88e8c340d2",
            "052af5b071f1474c8d71100454fd3a4c",
            "d1a2901d4ce640f0acac871f0894713a",
            "f437d7b3d34048f69cfc97ae6b084b16",
            "508b45592cec49e39418f56a0358ad88",
            "1fb2e1e97689447099fa109d32e37d76",
            "9cd9562f461747fcbbec00a12ee5c922",
            "08c3b684188749eebb22278ee4f1b784",
            "c838ba2321504192a2311076b2f3ca09",
            "752521d8b2254863870e6cb444839b46",
            "55aeaa26693a49e4aec666c408dfd72c",
            "16ba65faf1e1496499c9acc181a7fd5b",
            "8a39c287d43346bab01b645e6fa45eeb",
            "bafa8cbff2c6430299b3ecadf2c3aee4",
            "378e25ecfc904779ba4bdbccbf6340ef",
            "61a0e1963ef643d3b04ebe7b80b3c725",
            "b19dd6f288ab4e1b880f4ae2178d975a",
            "c9e617512c5e45529070603aab123686",
            "b4273383e13944da9e981452686c09a1",
            "ed8d856bc6024e27944eed0250bf8e16",
            "9a38e806c326451ea7af9ebe4097c5e5",
            "3df0a767e4c04095afec3d97e252fb17",
            "1d32185aac1a414496c10f6c875941dc",
            "d8a4f21cc9d14194a79cfa7c339509a4",
            "6af060f37c384fc1aaa6605d3c9641c4",
            "cdc0d8ebb8164e7eb8cfc09a2eb2fd62",
            "6aa760f206ae42d7a6929ee6c728479e",
            "d02f33ae78574576ae1828322e435349",
            "5d7673ab3ff2437d98019910be18c22b",
            "de687e329ed74eb2ae3798f7d1354c82",
            "01f4133bee21405287c4b1826d7b3d86",
            "c1a57118186948ba8b489aa14750dbc7",
            "cb124ed4b0824e0aa40ae402a76c35cd",
            "dbd7b7ca555e4edc9bdc349ac7c8a583",
            "9cd1f7bb766d432ebacb2934a29a8cf6",
            "35d41c38b0d842399e68e468cb6e2e2d",
            "ac5d6df6d96a444ca43f473f85924d2f",
            "cf0bbb3c15e645e49266351b7a8b88b6",
            "4b797b5218084663bd771d652a393644",
            "0562ced18c5c48cb83420b9cc979dde7",
            "a00cd44e244b46c0848adf10de44581e",
            "7734b0b0702149c6a85aeacb5804b5bb",
            "6d0a4f537466427f957e1c2a2ce2cc33",
            "bf5ac657b1b1432396f3a77a658b24ca",
            "f90a9e6870884486b0cc83ae05ade586",
            "0e4e59b8b5214a398317f1cc601a8868",
            "4b29bad46a514f37a15f8fa8f021b1e8",
            "e86fde28f2924961b07fe1f1b0e9f89c",
            "802b27ee38e7470da7d72810e3f1ad1c",
            "731e2691b68e41fcb1584a01391d3f29",
            "f8d194a931d943ae90d96db37cf81e87",
            "48f4004cea0843dba82b292a282e59e9",
            "ec49c7e5feff48428f052182dfd15e9c",
            "355ada44a74e4179ad31d08ca189065a",
            "0329247f0c354041b55f858a797cd5e7",
            "dc10a4d4fcb94197a3c157472f424ccf",
            "bb806ddc2f2746c59f6e9d98e88c8b34",
            "f497d6423ef74e7b80f1ba93f19eda15",
            "fd97b994f9594ab1baaf10defb128cf7",
            "d8fcb3a5018745dcb1eda1829355f442",
            "5ae1dd2e698846eabeedf60e53b4cef2",
            "c982a0d21f654640bbfd86cb963b9d20",
            "605f25c859a5470db7f22b3b2a174c69",
            "26096fbc53c4426d87ef16f63592957a",
            "db0785fe315a4c95a308983831b9d8ec",
            "6f801c13ea2c4258a9fdb76dba5aeb03",
            "47bd4eab327c4347b19b426ac2620345",
            "043861a88d304458817481bcaf1caa8b",
            "dd51667296494cb1b85422f72c964fcf",
            "4ab7d5b553ae4be2aac91a5c3342d677",
            "c8ca36f86e684ce495d262e1863c7184",
            "ce55764e947f4c058d654a53c96eb7a3",
            "d4f8b0507f6347e0bb4f43e8afc86bb8",
            "607acb10b0c04a1a88536e29defb382c",
            "3f7ce7c20c9b4070a8cd83f8fafddc13",
            "4b320dc122c1411f859c1e2c7370f130",
            "ee2bba7c62134fafa16f785eccdb39da",
            "939caddbcbab43c386e12768897229da",
            "5876fe72931f45b484edd6aa3538cbcf",
            "142856c2ef1548a0b180e4c9ebb94a9a",
            "1b26057acb164bbf818c9c407e67f813",
            "aec3ce3bee844d728cc63cce3a357119",
            "d44af8595f7c45898788f44869ab73b9",
            "c316a9d3945e482f8ce0ec65f6056ccc",
            "bf7cbd1e8c1d49faab86fb4232f70454",
            "47c3b837e2c04d92a29850c59fdbbc66",
            "d4df1773c85544618893895ddbd8651e",
            "c043bfd0babf4126b7d1947628e84937",
            "c1a266ba21ce4c1d8c9bcf74823e7b7a",
            "5e15deb82eeb4d77b9398c8f500bd1e0",
            "6ea72273b8c441e0929ac081adfd770d",
            "cb2d3ffeabc5436ab660ee25fdd93f56",
            "5733da8b7a7a46a69abd6654bf9d7559",
            "e72cfff68d274570ab80211bb3bcb11f",
            "8c223a2c2a5d4a208e6d17120a3e1874",
            "46a8594c676d4822b325dfa8cb05ee34",
            "e8c06f693c8d49f2b6638632b729b233",
            "05f71f3c372f4fcbb11d2e4ce37df695",
            "184731135f954c72a039e47944198931",
            "29ac56cd3afe407c8154a9eabec3ac19",
            "90ae719d06c74800adfee38a86bd8542",
            "d05f695195e14a2d9186c5c8a8b61881",
            "baf9ad92e4264fe6979e2d1eccb1853c",
            "c0ad52faa4d149b5beee0a210dee21da",
            "5193b7c66d464aa9a5b52e3fbc75c63b",
            "7169de7405ca403390217d71edc603d1",
            "d3af5a5e7fb7411592fce82c0570f342",
            "2d4cea086fa943f89efe9b2d2dacccfd",
            "35ddee0c79b9455aa9e1f54e56ff28fd",
            "c205f6592b264fd78d48ca94dd1903f0",
            "553ec8f514e14df2b5da182dd2081a79",
            "242a87f62c3442f5aeb691835a874877",
            "17d5240501d8475e83f3363be7612f55",
            "658f1a69d10f46b9a26ecec631165956",
            "49bab1c3dbdb4298af236ed4f9f407b9",
            "295e2d5d48e745f5a8c77f39bdc37d01",
            "c1694c4b3fdc435385795b730af5980b",
            "62834d6a61c2485ab3f6e58790deded8",
            "1adf3d611a134b57bbeeeaa2526f7170",
            "08cccf8d277f4ed98b2180224ef952cb",
            "a8bc5b6811d0481e952c93187df4bce6",
            "b2359cc220ee4394ac41cb48b474c1c4",
            "a48b4e939c14472b8260122693a0d847",
            "9fb4c2ad70df41ce8f8c529d49cc8df9",
            "e0960b14392c4c6a8be2d3bf0ca48992",
            "7824d1e698b44c1b81a36db0e5122255",
            "a17cf8374fb84b8484af7e5db3e73c47",
            "0b10dccf4297437191821f72850e9419",
            "2074e2af9e4043ebb5439dc74c51a774",
            "70ff48ff87614c30832d5b41b6803c57",
            "8308adda26ce41558adff44e0b54fd88",
            "a6a5a715cac04239b31a7a8452abad2c",
            "be18e504667749e0bc1efec300ed2c4b",
            "20e6e07b062941c7b98c56d879c228fd",
            "b160ce8eb1a34e559e1f88a9cbbecb11",
            "21dcf3cdabc047488356b910c2d4c6de",
            "6e57bb8f15264009bee6100ac6703105",
            "e9f87863e9654395b03309359b360092",
            "ba7172d6c4a640bbb7525ad48c66434d",
            "9f4fc36b1181428db20f96e1e376123f",
            "a8ccf1772b8d419fa0b59abe89c7ff2d",
            "1140df6086354daea4acab9269937a98",
            "fdfb2e5292a548beadade3df4b25f8f2",
            "c7f2efcab7ae46d3a1d50ec2fc94e41e",
            "d8d63290b23d4977b26ef7f47419224c",
            "df223f4a34e7423ab885cb6468a9d74a",
            "900a6d0e2f9746f68dfb6100617443f1",
            "22c0b49342414b0ea1f32fd4ee05d723",
            "74a369420cc942998f014b8e2d694ffc",
            "eee88f640382463cb9fdb8503704fd1f"
          ]
        },
        "id": "T_MER5KGaQpk",
        "outputId": "7d26ebfb-0881-4fd1-fd35-1514a8607ce5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3168cf8f28c847eab14efef90653094a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/663 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0803f9e6c2604059b266b62f22654d03",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72baeb12126a4cad99928c92ebb8bee6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 8 files:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7bd1d132b760432692d67b9b465cb8ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00005-of-00008.safetensors:   0%|          | 0.00/3.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08c3b684188749eebb22278ee4f1b784",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00003-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4273383e13944da9e981452686c09a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00007-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de687e329ed74eb2ae3798f7d1354c82",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00008.safetensors:   0%|          | 0.00/3.89G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a00cd44e244b46c0848adf10de44581e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00004-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48f4004cea0843dba82b292a282e59e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00006-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "605f25c859a5470db7f22b3b2a174c69",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00008.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "607acb10b0c04a1a88536e29defb382c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00008-of-00008.safetensors:   0%|          | 0.00/1.70G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf7cbd1e8c1d49faab86fb4232f70454",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46a8594c676d4822b325dfa8cb05ee34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d3af5a5e7fb7411592fce82c0570f342",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "62834d6a61c2485ab3f6e58790deded8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2074e2af9e4043ebb5439dc74c51a774",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f4fc36b1181428db20f96e1e376123f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "finetuned_model_id = \"/content/resources/llm-finetuning/Models/checkpoint-520/\"\n",
        "# finetuned_model_id = \"Qwen/Qwen2.5-14B-Instruct\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    finetuned_model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype = None\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(finetuned_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "o7JMMXLjaQpl"
      },
      "outputs": [],
      "source": [
        "def generate_resp(qa_message):\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        qa_message,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "    )\n",
        "\n",
        "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "    generated_ids = model.generate(\n",
        "        model_inputs.input_ids,\n",
        "        max_new_tokens=1024,\n",
        "        do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        "    )\n",
        "\n",
        "    generated_ids = [\n",
        "        output_ids[len(input_ids):]\n",
        "        for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "    ]\n",
        "\n",
        "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7EqPuazRoJTn"
      },
      "outputs": [],
      "source": [
        "question_text = [{\"role\": \"user\",\"content\": \"ما هي المظاهر الاقتصادية فى دولة مصر ؟\"}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKnvRibIJqKR",
        "outputId": "962ab188-ff6a-4ea1-ae54-dba8871ee279"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "\n",
            "تُهيمن القطاعات الخدمية (قناة السويس، السياحة، الاتصالات) على الهيكل الاقتصادي المصري، بينما تشهد القطاعات الإنتاجية (التصنيع، الزراعة، الطاقة) نموًا قويًا مدعومًا بمشروعات البنية التحتية الكبرى والاستثمارات الحكومية.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "response = generate_resp(question_text)\n",
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntWp9aKNaQpl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "6aJ-gLTRf3nI",
        "93gnVs9KaQpa",
        "-IhZJy5SaQpd",
        "j6PjrQ7waQpe",
        "JwIEdWfwaQpf",
        "1MfedtDJaQpg",
        "TtSGhiQCaQpg",
        "k44-yv07aQph"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31090,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01f4133bee21405287c4b1826d7b3d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cd1f7bb766d432ebacb2934a29a8cf6",
            "placeholder": "​",
            "style": "IPY_MODEL_35d41c38b0d842399e68e468cb6e2e2d",
            "value": "model-00001-of-00008.safetensors: 100%"
          }
        },
        "0329247f0c354041b55f858a797cd5e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ae1dd2e698846eabeedf60e53b4cef2",
            "placeholder": "​",
            "style": "IPY_MODEL_c982a0d21f654640bbfd86cb963b9d20",
            "value": " 4.00G/4.00G [15:12&lt;00:00, 9.21MB/s]"
          }
        },
        "043861a88d304458817481bcaf1caa8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "052af5b071f1474c8d71100454fd3a4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0562ced18c5c48cb83420b9cc979dde7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "05f71f3c372f4fcbb11d2e4ce37df695": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baf9ad92e4264fe6979e2d1eccb1853c",
            "max": 242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0ad52faa4d149b5beee0a210dee21da",
            "value": 242
          }
        },
        "069b332562544db5bed4b792110e13c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cbf3d723ada4fba8a44308d149d1402",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df5c778bbff0496cb3841ea2c8d83bc7",
            "value": 1
          }
        },
        "0803f9e6c2604059b266b62f22654d03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_27d64f4ec9bf4613a8d86bb4f5bab3a4",
              "IPY_MODEL_069b332562544db5bed4b792110e13c6",
              "IPY_MODEL_7ed4f8b20b4c4390af731f5b1417165c"
            ],
            "layout": "IPY_MODEL_97538235fa3b4b7d974cb991f09b5427"
          }
        },
        "08c3b684188749eebb22278ee4f1b784": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c838ba2321504192a2311076b2f3ca09",
              "IPY_MODEL_752521d8b2254863870e6cb444839b46",
              "IPY_MODEL_55aeaa26693a49e4aec666c408dfd72c"
            ],
            "layout": "IPY_MODEL_16ba65faf1e1496499c9acc181a7fd5b"
          }
        },
        "08cccf8d277f4ed98b2180224ef952cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0960b14392c4c6a8be2d3bf0ca48992",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7824d1e698b44c1b81a36db0e5122255",
            "value": 1
          }
        },
        "0b10dccf4297437191821f72850e9419": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0e4e59b8b5214a398317f1cc601a8868": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1140df6086354daea4acab9269937a98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_900a6d0e2f9746f68dfb6100617443f1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22c0b49342414b0ea1f32fd4ee05d723",
            "value": 1
          }
        },
        "12fd063b2fe64b979380efcca758e8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_052af5b071f1474c8d71100454fd3a4c",
            "placeholder": "​",
            "style": "IPY_MODEL_d1a2901d4ce640f0acac871f0894713a",
            "value": "model-00005-of-00008.safetensors: 100%"
          }
        },
        "142856c2ef1548a0b180e4c9ebb94a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16ba65faf1e1496499c9acc181a7fd5b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17d5240501d8475e83f3363be7612f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "184731135f954c72a039e47944198931": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5193b7c66d464aa9a5b52e3fbc75c63b",
            "placeholder": "​",
            "style": "IPY_MODEL_7169de7405ca403390217d71edc603d1",
            "value": " 242/242 [00:00&lt;00:00, 19.9kB/s]"
          }
        },
        "1adf3d611a134b57bbeeeaa2526f7170": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a48b4e939c14472b8260122693a0d847",
            "placeholder": "​",
            "style": "IPY_MODEL_9fb4c2ad70df41ce8f8c529d49cc8df9",
            "value": "vocab.json: "
          }
        },
        "1b26057acb164bbf818c9c407e67f813": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d32185aac1a414496c10f6c875941dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5693e0ee2144448feee08ebbc8d02c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1fb2e1e97689447099fa109d32e37d76": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2074e2af9e4043ebb5439dc74c51a774": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70ff48ff87614c30832d5b41b6803c57",
              "IPY_MODEL_8308adda26ce41558adff44e0b54fd88",
              "IPY_MODEL_a6a5a715cac04239b31a7a8452abad2c"
            ],
            "layout": "IPY_MODEL_be18e504667749e0bc1efec300ed2c4b"
          }
        },
        "20e6e07b062941c7b98c56d879c228fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21dcf3cdabc047488356b910c2d4c6de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "22c0b49342414b0ea1f32fd4ee05d723": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "242a87f62c3442f5aeb691835a874877": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26096fbc53c4426d87ef16f63592957a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_043861a88d304458817481bcaf1caa8b",
            "placeholder": "​",
            "style": "IPY_MODEL_dd51667296494cb1b85422f72c964fcf",
            "value": "model-00002-of-00008.safetensors: 100%"
          }
        },
        "27d64f4ec9bf4613a8d86bb4f5bab3a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a17c84a585e84d90a0cdc3a0a9bebc0c",
            "placeholder": "​",
            "style": "IPY_MODEL_30813041b1ef4df698fb7d7108110764",
            "value": "model.safetensors.index.json: "
          }
        },
        "295e2d5d48e745f5a8c77f39bdc37d01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29ac56cd3afe407c8154a9eabec3ac19": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d4cea086fa943f89efe9b2d2dacccfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_242a87f62c3442f5aeb691835a874877",
            "placeholder": "​",
            "style": "IPY_MODEL_17d5240501d8475e83f3363be7612f55",
            "value": "tokenizer_config.json: "
          }
        },
        "2f0ec1b42e4e46c6b018bb71fd92e9a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f70fc35377d049a39ae95af415d74a84",
            "placeholder": "​",
            "style": "IPY_MODEL_d82d7baa005f41aab07e4132b3e496f4",
            "value": " 663/663 [00:00&lt;00:00, 20.0kB/s]"
          }
        },
        "30813041b1ef4df698fb7d7108110764": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "309fef4258f445cc98245f88e8c340d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3168cf8f28c847eab14efef90653094a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ee93bfe50474b9180fdec8406e7c54f",
              "IPY_MODEL_8928a77a1b584e4db7586e38859c2739",
              "IPY_MODEL_2f0ec1b42e4e46c6b018bb71fd92e9a4"
            ],
            "layout": "IPY_MODEL_48f3725fc243472586bbfc9a061db32d"
          }
        },
        "355ada44a74e4179ad31d08ca189065a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd97b994f9594ab1baaf10defb128cf7",
            "max": 3995328080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8fcb3a5018745dcb1eda1829355f442",
            "value": 3995328080
          }
        },
        "35d41c38b0d842399e68e468cb6e2e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "35ddee0c79b9455aa9e1f54e56ff28fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_658f1a69d10f46b9a26ecec631165956",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49bab1c3dbdb4298af236ed4f9f407b9",
            "value": 1
          }
        },
        "378e25ecfc904779ba4bdbccbf6340ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "395f0fd2b7644d728016146af81d7682": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3df0a767e4c04095afec3d97e252fb17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d02f33ae78574576ae1828322e435349",
            "placeholder": "​",
            "style": "IPY_MODEL_5d7673ab3ff2437d98019910be18c22b",
            "value": " 4.00G/4.00G [15:11&lt;00:00, 7.17MB/s]"
          }
        },
        "3ee93bfe50474b9180fdec8406e7c54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6064bda9cefb4567abd50d8b8b5c1dc3",
            "placeholder": "​",
            "style": "IPY_MODEL_cea925fe80bc4d26b1f89f6ca44ad764",
            "value": "config.json: 100%"
          }
        },
        "3f7ce7c20c9b4070a8cd83f8fafddc13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5876fe72931f45b484edd6aa3538cbcf",
            "placeholder": "​",
            "style": "IPY_MODEL_142856c2ef1548a0b180e4c9ebb94a9a",
            "value": "model-00008-of-00008.safetensors: 100%"
          }
        },
        "421be503e61e46389d4e345983257a43": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46a8594c676d4822b325dfa8cb05ee34": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8c06f693c8d49f2b6638632b729b233",
              "IPY_MODEL_05f71f3c372f4fcbb11d2e4ce37df695",
              "IPY_MODEL_184731135f954c72a039e47944198931"
            ],
            "layout": "IPY_MODEL_29ac56cd3afe407c8154a9eabec3ac19"
          }
        },
        "47bd4eab327c4347b19b426ac2620345": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47c3b837e2c04d92a29850c59fdbbc66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e15deb82eeb4d77b9398c8f500bd1e0",
            "placeholder": "​",
            "style": "IPY_MODEL_6ea72273b8c441e0929ac081adfd770d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "48f3725fc243472586bbfc9a061db32d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48f4004cea0843dba82b292a282e59e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec49c7e5feff48428f052182dfd15e9c",
              "IPY_MODEL_355ada44a74e4179ad31d08ca189065a",
              "IPY_MODEL_0329247f0c354041b55f858a797cd5e7"
            ],
            "layout": "IPY_MODEL_dc10a4d4fcb94197a3c157472f424ccf"
          }
        },
        "49bab1c3dbdb4298af236ed4f9f407b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ab7d5b553ae4be2aac91a5c3342d677": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b29bad46a514f37a15f8fa8f021b1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b320dc122c1411f859c1e2c7370f130": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b26057acb164bbf818c9c407e67f813",
            "max": 1698703696,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aec3ce3bee844d728cc63cce3a357119",
            "value": 1698703696
          }
        },
        "4b797b5218084663bd771d652a393644": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "508b45592cec49e39418f56a0358ad88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5193b7c66d464aa9a5b52e3fbc75c63b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "529ff264df854d058e67532e60f1a2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "553ec8f514e14df2b5da182dd2081a79": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55aeaa26693a49e4aec666c408dfd72c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b19dd6f288ab4e1b880f4ae2178d975a",
            "placeholder": "​",
            "style": "IPY_MODEL_c9e617512c5e45529070603aab123686",
            "value": " 4.00G/4.00G [12:47&lt;00:00, 4.00MB/s]"
          }
        },
        "5733da8b7a7a46a69abd6654bf9d7559": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5876fe72931f45b484edd6aa3538cbcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ae1dd2e698846eabeedf60e53b4cef2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d7673ab3ff2437d98019910be18c22b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e15deb82eeb4d77b9398c8f500bd1e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605f25c859a5470db7f22b3b2a174c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_26096fbc53c4426d87ef16f63592957a",
              "IPY_MODEL_db0785fe315a4c95a308983831b9d8ec",
              "IPY_MODEL_6f801c13ea2c4258a9fdb76dba5aeb03"
            ],
            "layout": "IPY_MODEL_47bd4eab327c4347b19b426ac2620345"
          }
        },
        "6064bda9cefb4567abd50d8b8b5c1dc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "607acb10b0c04a1a88536e29defb382c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f7ce7c20c9b4070a8cd83f8fafddc13",
              "IPY_MODEL_4b320dc122c1411f859c1e2c7370f130",
              "IPY_MODEL_ee2bba7c62134fafa16f785eccdb39da"
            ],
            "layout": "IPY_MODEL_939caddbcbab43c386e12768897229da"
          }
        },
        "61a0e1963ef643d3b04ebe7b80b3c725": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62834d6a61c2485ab3f6e58790deded8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1adf3d611a134b57bbeeeaa2526f7170",
              "IPY_MODEL_08cccf8d277f4ed98b2180224ef952cb",
              "IPY_MODEL_a8bc5b6811d0481e952c93187df4bce6"
            ],
            "layout": "IPY_MODEL_b2359cc220ee4394ac41cb48b474c1c4"
          }
        },
        "658f1a69d10f46b9a26ecec631165956": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "68cebe69ad8046f28c770350dc23f7f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aa760f206ae42d7a6929ee6c728479e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6af060f37c384fc1aaa6605d3c9641c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cbf3d723ada4fba8a44308d149d1402": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6d0a4f537466427f957e1c2a2ce2cc33": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e86fde28f2924961b07fe1f1b0e9f89c",
            "max": 3995338432,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_802b27ee38e7470da7d72810e3f1ad1c",
            "value": 3995338432
          }
        },
        "6e57bb8f15264009bee6100ac6703105": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ea72273b8c441e0929ac081adfd770d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f801c13ea2c4258a9fdb76dba5aeb03": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce55764e947f4c058d654a53c96eb7a3",
            "placeholder": "​",
            "style": "IPY_MODEL_d4f8b0507f6347e0bb4f43e8afc86bb8",
            "value": " 4.00G/4.00G [15:13&lt;00:00, 10.7MB/s]"
          }
        },
        "70ff48ff87614c30832d5b41b6803c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20e6e07b062941c7b98c56d879c228fd",
            "placeholder": "​",
            "style": "IPY_MODEL_b160ce8eb1a34e559e1f88a9cbbecb11",
            "value": "merges.txt: "
          }
        },
        "7169de7405ca403390217d71edc603d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "723ee12bd10a4391aca27c36a90a2ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72595e3fb5a744fba818852f6802c02d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f437d7b3d34048f69cfc97ae6b084b16",
            "max": 3979624824,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_508b45592cec49e39418f56a0358ad88",
            "value": 3979624824
          }
        },
        "72baeb12126a4cad99928c92ebb8bee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a6c3804417b49e4b35ee3083a10fac9",
              "IPY_MODEL_a1b51e474553440db9a8cefefd9e1f97",
              "IPY_MODEL_f160162556e5428982f0e9a069335d37"
            ],
            "layout": "IPY_MODEL_68cebe69ad8046f28c770350dc23f7f7"
          }
        },
        "731e2691b68e41fcb1584a01391d3f29": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74a369420cc942998f014b8e2d694ffc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "752521d8b2254863870e6cb444839b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_378e25ecfc904779ba4bdbccbf6340ef",
            "max": 3995328080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61a0e1963ef643d3b04ebe7b80b3c725",
            "value": 3995328080
          }
        },
        "7734b0b0702149c6a85aeacb5804b5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e4e59b8b5214a398317f1cc601a8868",
            "placeholder": "​",
            "style": "IPY_MODEL_4b29bad46a514f37a15f8fa8f021b1e8",
            "value": "model-00004-of-00008.safetensors: 100%"
          }
        },
        "7824d1e698b44c1b81a36db0e5122255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7baa9226ead74c18a2dca0f5da58a31b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bd1d132b760432692d67b9b465cb8ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12fd063b2fe64b979380efcca758e8c6",
              "IPY_MODEL_72595e3fb5a744fba818852f6802c02d",
              "IPY_MODEL_c3cbd1237aef458980d6b1c6d703e99d"
            ],
            "layout": "IPY_MODEL_309fef4258f445cc98245f88e8c340d2"
          }
        },
        "7ed4f8b20b4c4390af731f5b1417165c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa4b3761bf3b4bd7ae9fc40bd3f09316",
            "placeholder": "​",
            "style": "IPY_MODEL_529ff264df854d058e67532e60f1a2aa",
            "value": " 47.5k/? [00:00&lt;00:00, 3.00MB/s]"
          }
        },
        "802b27ee38e7470da7d72810e3f1ad1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8308adda26ce41558adff44e0b54fd88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21dcf3cdabc047488356b910c2d4c6de",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e57bb8f15264009bee6100ac6703105",
            "value": 1
          }
        },
        "88abb58611774c068e1f3632f0f97879": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8928a77a1b584e4db7586e38859c2739": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_395f0fd2b7644d728016146af81d7682",
            "max": 663,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_723ee12bd10a4391aca27c36a90a2ec7",
            "value": 663
          }
        },
        "8a39c287d43346bab01b645e6fa45eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a6c3804417b49e4b35ee3083a10fac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9728c598fe444ce78b14c9af23b7df77",
            "placeholder": "​",
            "style": "IPY_MODEL_1d5693e0ee2144448feee08ebbc8d02c",
            "value": "Fetching 8 files: 100%"
          }
        },
        "8c223a2c2a5d4a208e6d17120a3e1874": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "900a6d0e2f9746f68dfb6100617443f1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "90ae719d06c74800adfee38a86bd8542": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "939caddbcbab43c386e12768897229da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9728c598fe444ce78b14c9af23b7df77": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97538235fa3b4b7d974cb991f09b5427": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a38e806c326451ea7af9ebe4097c5e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdc0d8ebb8164e7eb8cfc09a2eb2fd62",
            "max": 3995328080,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6aa760f206ae42d7a6929ee6c728479e",
            "value": 3995328080
          }
        },
        "9cd1f7bb766d432ebacb2934a29a8cf6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cd9562f461747fcbbec00a12ee5c922": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f4fc36b1181428db20f96e1e376123f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a8ccf1772b8d419fa0b59abe89c7ff2d",
              "IPY_MODEL_1140df6086354daea4acab9269937a98",
              "IPY_MODEL_fdfb2e5292a548beadade3df4b25f8f2"
            ],
            "layout": "IPY_MODEL_c7f2efcab7ae46d3a1d50ec2fc94e41e"
          }
        },
        "9fb4c2ad70df41ce8f8c529d49cc8df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a00cd44e244b46c0848adf10de44581e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7734b0b0702149c6a85aeacb5804b5bb",
              "IPY_MODEL_6d0a4f537466427f957e1c2a2ce2cc33",
              "IPY_MODEL_bf5ac657b1b1432396f3a77a658b24ca"
            ],
            "layout": "IPY_MODEL_f90a9e6870884486b0cc83ae05ade586"
          }
        },
        "a17c84a585e84d90a0cdc3a0a9bebc0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a17cf8374fb84b8484af7e5db3e73c47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1b51e474553440db9a8cefefd9e1f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_421be503e61e46389d4e345983257a43",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88abb58611774c068e1f3632f0f97879",
            "value": 8
          }
        },
        "a48b4e939c14472b8260122693a0d847": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6a5a715cac04239b31a7a8452abad2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9f87863e9654395b03309359b360092",
            "placeholder": "​",
            "style": "IPY_MODEL_ba7172d6c4a640bbb7525ad48c66434d",
            "value": " 1.67M/? [00:00&lt;00:00, 21.3MB/s]"
          }
        },
        "a8bc5b6811d0481e952c93187df4bce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a17cf8374fb84b8484af7e5db3e73c47",
            "placeholder": "​",
            "style": "IPY_MODEL_0b10dccf4297437191821f72850e9419",
            "value": " 2.78M/? [00:00&lt;00:00, 49.5MB/s]"
          }
        },
        "a8ccf1772b8d419fa0b59abe89c7ff2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8d63290b23d4977b26ef7f47419224c",
            "placeholder": "​",
            "style": "IPY_MODEL_df223f4a34e7423ab885cb6468a9d74a",
            "value": "tokenizer.json: "
          }
        },
        "ac5d6df6d96a444ca43f473f85924d2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aec3ce3bee844d728cc63cce3a357119": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b160ce8eb1a34e559e1f88a9cbbecb11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b19dd6f288ab4e1b880f4ae2178d975a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2359cc220ee4394ac41cb48b474c1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4273383e13944da9e981452686c09a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed8d856bc6024e27944eed0250bf8e16",
              "IPY_MODEL_9a38e806c326451ea7af9ebe4097c5e5",
              "IPY_MODEL_3df0a767e4c04095afec3d97e252fb17"
            ],
            "layout": "IPY_MODEL_1d32185aac1a414496c10f6c875941dc"
          }
        },
        "b9c51f26f8a24c28957afd7bca9c6fd7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba7172d6c4a640bbb7525ad48c66434d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baf9ad92e4264fe6979e2d1eccb1853c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bafa8cbff2c6430299b3ecadf2c3aee4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb806ddc2f2746c59f6e9d98e88c8b34": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be18e504667749e0bc1efec300ed2c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf5ac657b1b1432396f3a77a658b24ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_731e2691b68e41fcb1584a01391d3f29",
            "placeholder": "​",
            "style": "IPY_MODEL_f8d194a931d943ae90d96db37cf81e87",
            "value": " 4.00G/4.00G [15:09&lt;00:00, 8.87MB/s]"
          }
        },
        "bf7cbd1e8c1d49faab86fb4232f70454": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47c3b837e2c04d92a29850c59fdbbc66",
              "IPY_MODEL_d4df1773c85544618893895ddbd8651e",
              "IPY_MODEL_c043bfd0babf4126b7d1947628e84937"
            ],
            "layout": "IPY_MODEL_c1a266ba21ce4c1d8c9bcf74823e7b7a"
          }
        },
        "c043bfd0babf4126b7d1947628e84937": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e72cfff68d274570ab80211bb3bcb11f",
            "placeholder": "​",
            "style": "IPY_MODEL_8c223a2c2a5d4a208e6d17120a3e1874",
            "value": " 8/8 [00:35&lt;00:00, 17.48s/it]"
          }
        },
        "c0ad52faa4d149b5beee0a210dee21da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1694c4b3fdc435385795b730af5980b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1a266ba21ce4c1d8c9bcf74823e7b7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1a57118186948ba8b489aa14750dbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac5d6df6d96a444ca43f473f85924d2f",
            "max": 3885154816,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf0bbb3c15e645e49266351b7a8b88b6",
            "value": 3885154816
          }
        },
        "c205f6592b264fd78d48ca94dd1903f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_295e2d5d48e745f5a8c77f39bdc37d01",
            "placeholder": "​",
            "style": "IPY_MODEL_c1694c4b3fdc435385795b730af5980b",
            "value": " 7.30k/? [00:00&lt;00:00, 482kB/s]"
          }
        },
        "c316a9d3945e482f8ce0ec65f6056ccc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3cbd1237aef458980d6b1c6d703e99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fb2e1e97689447099fa109d32e37d76",
            "placeholder": "​",
            "style": "IPY_MODEL_9cd9562f461747fcbbec00a12ee5c922",
            "value": " 3.98G/3.98G [14:21&lt;00:00, 2.43MB/s]"
          }
        },
        "c7f2efcab7ae46d3a1d50ec2fc94e41e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c838ba2321504192a2311076b2f3ca09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a39c287d43346bab01b645e6fa45eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_bafa8cbff2c6430299b3ecadf2c3aee4",
            "value": "model-00003-of-00008.safetensors: 100%"
          }
        },
        "c8ca36f86e684ce495d262e1863c7184": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c982a0d21f654640bbfd86cb963b9d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9e617512c5e45529070603aab123686": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb124ed4b0824e0aa40ae402a76c35cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b797b5218084663bd771d652a393644",
            "placeholder": "​",
            "style": "IPY_MODEL_0562ced18c5c48cb83420b9cc979dde7",
            "value": " 3.89G/3.89G [14:47&lt;00:00, 5.27MB/s]"
          }
        },
        "cb2d3ffeabc5436ab660ee25fdd93f56": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cdc0d8ebb8164e7eb8cfc09a2eb2fd62": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce55764e947f4c058d654a53c96eb7a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cea925fe80bc4d26b1f89f6ca44ad764": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf0bbb3c15e645e49266351b7a8b88b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d02f33ae78574576ae1828322e435349": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d05f695195e14a2d9186c5c8a8b61881": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1a2901d4ce640f0acac871f0894713a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3af5a5e7fb7411592fce82c0570f342": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2d4cea086fa943f89efe9b2d2dacccfd",
              "IPY_MODEL_35ddee0c79b9455aa9e1f54e56ff28fd",
              "IPY_MODEL_c205f6592b264fd78d48ca94dd1903f0"
            ],
            "layout": "IPY_MODEL_553ec8f514e14df2b5da182dd2081a79"
          }
        },
        "d44af8595f7c45898788f44869ab73b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4df1773c85544618893895ddbd8651e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb2d3ffeabc5436ab660ee25fdd93f56",
            "max": 8,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5733da8b7a7a46a69abd6654bf9d7559",
            "value": 8
          }
        },
        "d4f8b0507f6347e0bb4f43e8afc86bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d82d7baa005f41aab07e4132b3e496f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8a4f21cc9d14194a79cfa7c339509a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8d63290b23d4977b26ef7f47419224c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8fcb3a5018745dcb1eda1829355f442": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db0785fe315a4c95a308983831b9d8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab7d5b553ae4be2aac91a5c3342d677",
            "max": 3995327992,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8ca36f86e684ce495d262e1863c7184",
            "value": 3995327992
          }
        },
        "dbd7b7ca555e4edc9bdc349ac7c8a583": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc10a4d4fcb94197a3c157472f424ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd51667296494cb1b85422f72c964fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de687e329ed74eb2ae3798f7d1354c82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01f4133bee21405287c4b1826d7b3d86",
              "IPY_MODEL_c1a57118186948ba8b489aa14750dbc7",
              "IPY_MODEL_cb124ed4b0824e0aa40ae402a76c35cd"
            ],
            "layout": "IPY_MODEL_dbd7b7ca555e4edc9bdc349ac7c8a583"
          }
        },
        "df223f4a34e7423ab885cb6468a9d74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df5c778bbff0496cb3841ea2c8d83bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0960b14392c4c6a8be2d3bf0ca48992": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e72cfff68d274570ab80211bb3bcb11f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e86fde28f2924961b07fe1f1b0e9f89c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8c06f693c8d49f2b6638632b729b233": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90ae719d06c74800adfee38a86bd8542",
            "placeholder": "​",
            "style": "IPY_MODEL_d05f695195e14a2d9186c5c8a8b61881",
            "value": "generation_config.json: 100%"
          }
        },
        "e9f87863e9654395b03309359b360092": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec49c7e5feff48428f052182dfd15e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb806ddc2f2746c59f6e9d98e88c8b34",
            "placeholder": "​",
            "style": "IPY_MODEL_f497d6423ef74e7b80f1ba93f19eda15",
            "value": "model-00006-of-00008.safetensors: 100%"
          }
        },
        "ed8d856bc6024e27944eed0250bf8e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8a4f21cc9d14194a79cfa7c339509a4",
            "placeholder": "​",
            "style": "IPY_MODEL_6af060f37c384fc1aaa6605d3c9641c4",
            "value": "model-00007-of-00008.safetensors: 100%"
          }
        },
        "ee2bba7c62134fafa16f785eccdb39da": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d44af8595f7c45898788f44869ab73b9",
            "placeholder": "​",
            "style": "IPY_MODEL_c316a9d3945e482f8ce0ec65f6056ccc",
            "value": " 1.70G/1.70G [06:05&lt;00:00, 5.28MB/s]"
          }
        },
        "eee88f640382463cb9fdb8503704fd1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f160162556e5428982f0e9a069335d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9c51f26f8a24c28957afd7bca9c6fd7",
            "placeholder": "​",
            "style": "IPY_MODEL_7baa9226ead74c18a2dca0f5da58a31b",
            "value": " 8/8 [15:13&lt;00:00, 380.75s/it]"
          }
        },
        "f437d7b3d34048f69cfc97ae6b084b16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f497d6423ef74e7b80f1ba93f19eda15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f70fc35377d049a39ae95af415d74a84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8d194a931d943ae90d96db37cf81e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f90a9e6870884486b0cc83ae05ade586": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa4b3761bf3b4bd7ae9fc40bd3f09316": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd97b994f9594ab1baaf10defb128cf7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdfb2e5292a548beadade3df4b25f8f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a369420cc942998f014b8e2d694ffc",
            "placeholder": "​",
            "style": "IPY_MODEL_eee88f640382463cb9fdb8503704fd1f",
            "value": " 7.03M/? [00:00&lt;00:00, 115MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
