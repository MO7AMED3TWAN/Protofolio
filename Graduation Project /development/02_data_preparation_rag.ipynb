{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12978273,"sourceType":"datasetVersion","datasetId":8214417}],"dockerImageVersionId":31090,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":1453.019756,"end_time":"2025-06-26T15:09:46.241755","environment_variables":{},"exception":true,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-06-26T14:45:33.221999","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"06324d1c","cell_type":"code","source":"!pip install numpy\n!pip install chromadb\n!pip install sentence-transformers\n!pip install langchain\n!pip install openai\n!pip install python-dotenv\n!pip install tiktoken\n!pip install langchain-community\n!pip install datasets\n!pip install optimum\n!pip install bitsandbytes\n!pip install bert_score\n!pip install transformers\n!pip install trl","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":1405.640289,"end_time":"2025-06-26T15:09:03.585206","exception":false,"start_time":"2025-06-26T14:45:37.944917","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2025-09-08T05:26:12.002120Z","iopub.execute_input":"2025-09-08T05:26:12.002339Z","iopub.status.idle":"2025-09-08T05:26:12.006367Z","shell.execute_reply.started":"2025-09-08T05:26:12.002314Z","shell.execute_reply":"2025-09-08T05:26:12.005581Z"}},"outputs":[],"execution_count":1},{"id":"ebb53619","cell_type":"markdown","source":"# Step 1 - Importing The Libraries","metadata":{"papermill":{"duration":0.007936,"end_time":"2025-06-26T15:09:03.602189","exception":false,"start_time":"2025-06-26T15:09:03.594253","status":"completed"},"tags":[]}},{"id":"f7f9c46e","cell_type":"code","source":"from langchain.embeddings import SentenceTransformerEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.llms import HuggingFacePipeline\nfrom langchain.vectorstores.utils import maximal_marginal_relevance\n\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\nfrom datasets import load_dataset\nimport chromadb\n\nfrom langchain.chains.query_constructor.schema import AttributeInfo\nfrom langchain.chains import RetrievalQA\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain.retrievers.document_compressors import LLMChainExtractor\nfrom langchain.schema import BaseRetriever, Document\n\nfrom dataclasses import dataclass\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n\nimport os\nimport numpy as np\nimport json\nimport pandas as pd\nimport time","metadata":{"papermill":{"duration":39.659517,"end_time":"2025-06-26T15:09:43.269854","exception":true,"start_time":"2025-06-26T15:09:03.610337","status":"failed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"9088d265","cell_type":"markdown","source":"# Step 2 - Loading Data","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"019e9141-4a52-4223-94aa-70d6beba79e7","cell_type":"code","source":"from langchain.embeddings import SentenceTransformerEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain_community.llms import HuggingFacePipeline\nfrom langchain.vectorstores.utils import maximal_marginal_relevance\n\nfrom sentence_transformers import SentenceTransformer\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\nfrom datasets import load_dataset\nimport chromadb\n\nfrom langchain.chains.query_constructor.schema import AttributeInfo\nfrom langchain.chains import RetrievalQA\nfrom langchain.retrievers import ContextualCompressionRetriever\nfrom langchain.retrievers.document_compressors import LLMChainExtractor\nfrom langchain.schema import BaseRetriever, Document\n\nfrom dataclasses import dataclass\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nfrom peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n\nimport os\nimport numpy as np\nimport json\nimport pandas as pd\nimport time","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"19f1174a","cell_type":"code","source":"def load_the_data(file_path):\n    \"\"\"Load and process the JSON file\"\"\"\n    try:\n        with open(file_path, 'r', encoding='utf-8') as file:\n            data = json.load(file)\n            \n        print(f\"Successfully loaded {len(data)} documents\")\n        return data\n        \n    except FileNotFoundError:\n        print(f\"File {file_path} not found!\")\n        return []\n    except json.JSONDecodeError as e:\n        print(f\"JSON decode error: {e}\")\n        return []\n    except Exception as e:\n        print(f\"Unexpected error: {e}\")\n        return []\n\ndef analyze_the_data(data):\n    \"\"\"Analyze the loaded data\"\"\"\n    if not data:\n        return\n    \n    # Create DataFrame\n    df = pd.DataFrame(data)\n    \n    print(\"\\nData Analysis:\")\n    print(f\"Total documents: {len(df)}\")\n    print(f\"Columns: {df.columns.tolist()}\")\n    \n    # Calculate text lengths\n    df['title_length'] = df['Title'].apply(len)\n    df['context_length'] = df['Context'].apply(len)\n    \n    print(f\"\\nText Length Statistics:\")\n    print(f\"Average title length: {df['title_length'].mean():.1f} characters\")\n    print(f\"Average context length: {df['context_length'].mean():.1f} characters\")\n    print(f\"Total context characters: {df['context_length'].sum():,}\")\n    \n    return df\n\ndef display_documents(data, max_display=5):\n    \"\"\"Display the documents in a readable format\"\"\"\n    print(f\"\\nDocuments (showing first {max_display}):\")\n    print(\"-\" * 50)\n    \n    for i, doc in enumerate(data[:max_display]):\n        print(f\"\\n{i+1}. {doc['Title']}\")\n        print(f\"   {doc['Context'][:100]}...\")\n        print(f\"   Length: {len(doc['Context'])} characters\")\n        print(\"-\" * 30)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"01e8c686-c609-4927-a36a-6a8071162f89","cell_type":"code","source":"file_path = \"/kaggle/input/laws-data/laws.json\"  # Replace with your actual file path\n    \n# Load the data\nwhole_data = load_the_data(file_path)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3b536495-54ed-4f7e-9659-cadd6c4d38aa","cell_type":"code","source":"if whole_data:    \n    # Display documents\n    display_documents(whole_data)\n\n    # Show Some Analysis\n    analyze_the_data(whole_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"e0a32120","cell_type":"markdown","source":"# Step 3 - Splitting Data","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"422464d6","cell_type":"code","source":"# train_data , test_data = train_test_split(whole_data, test_size=0.1, random_state=1)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"dff641a1","cell_type":"markdown","source":"# Step 4 - Document Creation","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"5db01bcb-fdf6-4e2a-b7ba-8ed51f9b20b0","cell_type":"code","source":"from langchain.schema import Document\n\ndef Create_documents(whole_data):\n    \"\"\"\n    Create documents suitable for embedding models\n    Returns: List of Document objects with combined text for embedding\n    \"\"\"\n    documents = []\n    \n    for item in whole_data:\n        if isinstance(item, list):\n            item = item[0]\n\n        title = item.get(\"Title\", \"\")\n        context = item.get(\"Context\", \"\")\n\n        if title and context:\n            # Combine title and context for better embedding quality\n            combined_text = f\"{title}\\n\\n{context}\"\n            \n            documents.append(Document(\n                page_content=combined_text,  # This is what gets embedded\n                metadata={\n                    \"title\": title,\n                    \"context\": context,\n                    \"source\": \"egypt_data\",\n                    \"text_length\": len(combined_text)\n                }\n            ))\n    \n    return documents","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"c90f157f-3e58-4665-9210-3412fd67e0a1","cell_type":"code","source":"# Usage:\ndocuments = Create_documents(whole_data)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3a6a941c-2619-402e-9db6-156b4b802fdd","cell_type":"code","source":"print(f\"Documents lenght : {len(documents)}\")\n\nfor i, doc in enumerate(documents[:3]):\n    print(f\"\\nDocument {i+1}:\")\n    print(f\"Title : {doc.page_content[:100]}...\")\n    print(f\"Meta Data : {doc.metadata}\")\n    print(\"-\" * 50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"3ca63793-8d5d-4c4e-8569-d62bb7b8d9f1","cell_type":"code","source":"# For embeddings, you'll use:\ntexts = [doc.page_content for doc in documents] \n\nprint(f\"Created {len(documents)} documents for embedding\")\nprint(f\"Sample text for embedding: {texts[4][:]}...\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"6ba1791b-53d0-4ae8-a674-d39dd2998b42","cell_type":"code","source":"whole_documents","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"f0a731ad","cell_type":"markdown","source":"# Step 5 - Embedding Model","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"eaa3f91b","cell_type":"code","source":"model_id = \"Alibaba-NLP/gte-multilingual-base\"\ndim = 768\n\ndevice = \"cuda:0\"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"f99b4d7a","cell_type":"code","source":"model = SentenceTransformer(model_id, device=device)\n\nembeddings = SentenceTransformerEmbeddings(\n    model_name=model_id,\n    model_kwargs={'device': device}\n)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"1e2f0622","cell_type":"code","source":"from sentence_transformers.util import batch_to_device\n  \ndef batch_encode(texts, model, batch_size=16):\n    embeddings = []\n    for i in range(0, len(texts), batch_size):\n        batch = texts[i:i + batch_size]\n        emb = model.encode(batch, show_progress_bar=False)\n        embeddings.extend(emb)\n    return embeddings\n \nencoded_docs = batch_encode(list(doc_texts.values()), model, batch_size=16)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"005d1f43","cell_type":"code","source":"Data_docs = [doc for doc in documents]\n\nData_texts = []\n\nfor doc in Data_docs:\n    Title = doc.metadata.get(\"title\")\n    Context = doc.metadata.get(\"context\")\n\nencoded_data = batch_encode(Data_texts, model, batch_size=16)\n\nencoded_data = [e.tolist() for e in encoded_data]","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"cfe9f208","cell_type":"markdown","source":"# Step 6 - Create The Vector Database - ChromaDB","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"16c9a60a","cell_type":"code","source":"chroma_client = chromadb.PersistentClient(path=\"./chromadb-ar-docs\")","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"deb4d4d8","cell_type":"code","source":"collection = chroma_client.create_collection(\n    name=\"ar_docs\",\n    metadata={\"hnsw:space\": \"cosine\"}\n)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"1527441c","cell_type":"code","source":"collection.add(\n    documents=doc_text,\n    embeddings=embedding_questions,\n    metadatas=QA_metadata,\n    ids=ids_to_add\n)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"17a491c7","cell_type":"code","source":"collection = chroma_client.get_or_create_collection(name=\"ar_docs\")","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"f5b1ef9f","cell_type":"code","source":"vectordb = Chroma(\n    collection_name=\"ar_docs\",\n    embedding_function=embeddings,\n    persist_directory=\"./chromadb-ar-docs\"\n)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"1fe30e24","cell_type":"code","source":"question = \"ما هي مظاهر الحياة السياسية بالدولة المصرية ؟\"\n\n\nquestion_embed = model.encode([question])[0].tolist()\n\nresults = collection.query(\n    query_embeddings=[question_embed],\n    n_results=3\n)\n\nprint(results)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"c21fd9a1","cell_type":"code","source":"if results[\"documents\"]:\n    top_match_metadata = results[\"metadatas\"][0][0]\n    Matched_Title = top_match_metadata.get(\"Title\", \"\")\n    Context = top_match_metadata.get(\"Context\")\n\n    print(\"Nearest Matched Titles: \", Matched_Title)\n    print(\"Context Of The Nearest Titles:\", Context)\n    \nelse:\n    print(\"No Find Any !!\")","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"0ab51cf5","cell_type":"markdown","source":"# Step 7 - Evaluation The embedding model","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"15623830","cell_type":"markdown","source":"### Similarity search","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"7040871a","cell_type":"code","source":"chroma_results = []\nqa_embeddings = []  \n\nfor embedding in encoded_questions:\n    results = vectordb.similarity_search_by_vector(\n        embedding=embedding, \n        k=3\n    )\n    chroma_results.append(results)\n    qa_embeddings.append(embedding)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"id":"e1d5fad0","cell_type":"markdown","source":"### Accuracy","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"id":"14176bc1","cell_type":"code","source":"chroma_insights = {\n    \"valid\": 0,\n    \"similar\": 0,\n    \"invalid\": 0\n}\n\nfor i in range(len(qa_texts)):\n    true_metadata = QA_metadata[i]  \n\n    pred_metadata = chroma_results[i][0].metadata\n\n    true_id = str(true_metadata.get(\"id\", \"\"))\n    pred_id = str(pred_metadata.get(\"id\", \"\"))\n\n    true_source = true_metadata.get(\"source\", \"\")\n    pred_source = pred_metadata.get(\"source\", \"\")\n\n    # تصنيف النتائج\n    if true_id == pred_id:\n        chroma_insights[\"valid\"] += 1\n    elif true_source == pred_source:\n        chroma_insights[\"similar\"] += 1\n    else:\n        chroma_insights[\"invalid\"] += 1\n\n# حساب النسب\ntotal = len(qa_texts)\nchroma_insights[\"valid_percentage\"] = chroma_insights[\"valid\"] / total\nchroma_insights[\"similar_percentage\"] = chroma_insights[\"similar\"] / total\nchroma_insights[\"invalid_percentage\"] = chroma_insights[\"invalid\"] / total\n\n# طباعة النتائج\nprint(\"Model ID:\", model_id)\nprint(\"----\")\nprint(\"Valid:\", chroma_insights[\"valid\"])\nprint(\"Valid%:\", chroma_insights[\"valid_percentage\"])\nprint(\"----\")\nprint(\"Similar:\", chroma_insights[\"similar\"])\nprint(\"Similar%:\", chroma_insights[\"similar_percentage\"])\nprint(\"----\")\nprint(\"Invalid:\", chroma_insights[\"invalid\"])\nprint(\"Invalid%:\", chroma_insights[\"invalid_percentage\"])\nprint(\"----\")","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"outputs":[],"execution_count":null}]}