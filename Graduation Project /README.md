# Speak with Your Book ğŸ“šğŸ’¬

An intelligent chatbot system that enables users to have meaningful conversations with any uploaded book or document using Retrieval-Augmented Generation (RAG) and Large Language Models.

## ğŸ¯ Project Overview

**Speak with Your Book** is an advanced RAG-based system that transforms static documents into interactive conversational partners. Users can upload books or documents and engage in natural language conversations, receiving accurate, context-aware answers grounded in the specific content of their uploaded materials.

### Key Features

- ğŸ“– **Interactive Document Conversations**: Chat naturally with any book or document
- ğŸ” **Semantic Search**: Intelligent retrieval of relevant content segments
- ğŸ¤– **Fine-tuned LLM**: Custom Qwen model optimized for document-based conversations
- ğŸ’¾ **Vector Database**: ChromaDB for efficient similarity search and retrieval
- ğŸŒ **User-Friendly Interface**: Clean UI for seamless interaction
- ğŸ”® **Future Arabic Support**: Planned multilingual capabilities

## ğŸ—ï¸ System Architecture

### Workflow Overview
   ## Part (1)
1. **Document Preprocessing**
   - Extract and clean text from uploaded documents
   - Segment content into meaningful units (chapters, paragraphs)
   - Generate vector embeddings for each segment

2. **Vector Storage**
   - Store embeddings in ChromaDB for fast semantic search
   - Index content for efficient retrieval

   ## Part (2)
3. **Query Processing**
   - Convert user questions into vector embeddings
   - Retrieve most relevant document segments
   - Feed context to fine-tuned LLM

4. **Response Generation**
   - Generate contextual responses using retrieved information
   - Ensure accuracy and coherence based on source material


## Workflow Digram
```
[Document Upload] â†’ [Preprocessing] â†’ [Embedding Generation] â†’ [ChromaDB Storage]
                                                                       â†“
[User Query] â†’ [Query Embedding] â†’ [Similarity Search] â†’ [Context Retrieval] â†’ [LLM Response]
```

## ğŸ“ Project Structure

```
speak-with-your-book/
â”œâ”€â”€ development/                          # Development Folder
â”‚   â”œâ”€â”€ 01_qwen_fine_tuning.ipynb         # Fine-tune Qwen LLM
â”‚   â”œâ”€â”€ 02_data_preparation_rag.ipynb     # RAG data prep & DB creation
â”‚   â”œâ”€â”€ inputs/
â”‚       â””â”€â”€ data/
â”‚           â”œâ”€â”€ pdf/                      # Original pdf documents
â”‚           â””â”€â”€ otherwise/                # JSON and other supported document formats
â”‚   â””â”€â”€ outputs/
â”‚         â””â”€â”€ data/
â”‚               â”œâ”€â”€ processed/            # Cleaned and segmented data
â”‚               â””â”€â”€ vector_database/      # Generated vector embeddings
â”‚         â””â”€â”€ Model/                      # Fine-tuned Model
â”œâ”€â”€ 03_rag_system.ipynb                   # Main RAG system implementation
â”œâ”€â”€ ui/streamlit_app.py                   # User interface
â”œâ”€â”€ requirements.txt                      # Python dependencies 
â”‚   
â””â”€â”€ README.md                     
```
## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- CUDA-compatible GPU (recommended for model training)
- Minimum 16GB RAM (32GB recommended)

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/speak-with-your-book.git
   cd speak-with-your-book
   ```

2. **Create virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

### Usage

#### Step 1: Fine-tune the LLM
Run the fine-tuning notebook to customize Qwen for your specific use case:
```bash
jupyter notebook notebooks/01_qwen_fine_tuning.ipynb
```

#### Step 2: Prepare RAG Data
Process your documents and create the vector database:
```bash
jupyter notebook notebooks/02_data_preparation_rag.ipynb
```

#### Step 3: Run the RAG System
Launch the main RAG system:
```bash
jupyter notebook notebooks/03_rag_system.ipynb
```

#### Step 4: Use the Interface (Optional)
Launch the user interface for easier interaction:
```bash
streamlit run ui/streamlit_app.py
```

## ğŸ“š System Components

### Main RAG System (`main_rag_system.ipynb`) - **ğŸ¯ Primary Interface**
- **Purpose**: Complete RAG system built with LangChain
- **Features**:
  - Load pre-built fine-tuned Qwen model
  - Connect to pre-built ChromaDB vector database
  - Interactive chat interface for book conversations
  - Query processing with context retrieval
  - Performance evaluation and metrics
  - **Ready to run immediately!**

### Development Notebooks (Reference Only)

#### Database Creation (`development/database_creation.ipynb`) - âœ… **Completed**
- **Purpose**: Built vector database from JSON files with RAG-optimized structure
- **Process**:
  - JSON file parsing and processing
  - Text chunking with optimal RAG structure
  - Embedding generation for semantic search
  - ChromaDB database creation and population
  - **Output**: Vector database ready for RAG system

#### Model Fine-tuning (`development/model_fine_tuning.ipynb`) - âœ… **Completed** 
- **Purpose**: Fine-tuned Qwen model specifically for RAG conversations
- **Process**:
  - Model configuration for document-based chat
  - Training data preparation and optimization
  - Fine-tuning with conversation-specific objectives
  - Model evaluation and validation
  - **Output**: Optimized model for RAG system

## ğŸ› ï¸ Technical Stack

- **Language Models**: Qwen (fine-tuned)
- **Vector Database**: ChromaDB
- **Embeddings**: Sentence Transformers / OpenAI Embeddings
- **Framework**: Python, Transformers, LangChain
- **Interface**: Jupyter Notebooks, Streamlit (planned)
- **Deployment**: Local development, cloud deployment ready

## ğŸ”® Future Enhancements

### Planned Features
- **Multi-format Support**: PDF, EPUB, DOCX, and more document types
- **Advanced Interactions**: Follow-up questions, conversation memory
- **Arabic Language Support**: Multilingual capabilities for Arabic documents
- **Web Interface**: Enhanced UI with document management
- **Batch Processing**: Handle multiple documents simultaneously
- **Export Options**: Save conversations and insights

### Technical Improvements
- **Hybrid Search**: Combine semantic and keyword search
- **Dynamic Chunking**: Adaptive text segmentation based on content
- **Model Optimization**: Quantization and efficiency improvements
- **Caching System**: Faster response times for repeated queries

## ğŸ¤ Contributing

We welcome contributions! Please see our contributing guidelines:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“ Support

If you encounter any issues or have questions:
- Open an issue on GitHub
- Check the documentation in the notebooks
- Review the troubleshooting section below

## ğŸ“ˆ Results and Examples

### Sample Interactions

**User**: "Ù…Ø§ Ø§Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¯ÙŠÙ…ÙˆØ¬Ø±Ø§ÙÙŠ Ù„Ù„Ù…Ø¬ØªÙ…Ø¹ Ø§Ù„Ù…ØµØ±ÙŠ"

**System**:  Ø§Ù„Ø¹Ø¯Ø¯ ÙˆØ§Ù„ÙƒØ«Ø§ÙØ©: Ø£ÙƒØ«Ø± Ù…Ù† 106 Ù…Ù„ÙŠÙˆÙ† Ù†Ø³Ù…Ø© (Ø§Ù„Ø£ÙƒØ¨Ø± Ø¹Ø±Ø¨ÙŠÙ‹Ø§)ØŒ ÙŠØ¹ÙŠØ´ 95% Ù…Ù†Ù‡Ù… Ø¹Ù„Ù‰ 4.5% ÙÙ‚Ø· Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø­Ø© (ÙˆØ§Ø¯ÙŠ Ø§Ù„Ù†ÙŠÙ„ ÙˆØ§Ù„Ø¯Ù„ØªØ§)ØŒ Ù…Ù…Ø§ ÙŠØ®Ù„Ù‚ ÙƒØ«Ø§ÙØ© Ø³ÙƒØ§Ù†ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø¬Ø¯Ù‹Ø§.

Ù…Ø¬ØªÙ…Ø¹ ÙØªÙŠ: Ù…Ø¬ØªÙ…Ø¹ Ø´Ø§Ø¨ Ø¨Ø´ÙƒÙ„ Ù„Ø§ÙØªØŒ Ø­ÙŠØ« Ø£ÙƒØ«Ø± Ù…Ù† 60% Ù…Ù† Ø§Ù„Ø³ÙƒØ§Ù† ØªØ­Øª Ø³Ù† 30 Ø¹Ø§Ù…Ù‹Ø§. Ù‡Ø°Ù‡ Ø³Ù…Ø© ØªÙ…Ø«Ù„ Ø·Ø§Ù‚Ø© Ø¨Ø´Ø±ÙŠØ© Ù‡Ø§Ø¦Ù„Ø© Ø¥Ø°Ø§ ØªÙ… Ø§Ø³ØªØ«Ù…Ø§Ø±Ù‡Ø§ØŒ ÙˆÙ„ÙƒÙ†Ù‡Ø§ ØªØ´ÙƒÙ„ Ø¶ØºØ·Ù‹Ø§ ÙƒØ¨ÙŠØ±Ù‹Ø§ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø¯Ù…Ø§Øª ÙˆØ³ÙˆÙ‚ Ø§Ù„Ø¹Ù…Ù„.

Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ù…Ùˆ: Ù…Ø±ØªÙØ¹ (Ø­ÙˆØ§Ù„ÙŠ 1.7% Ø³Ù†ÙˆÙŠÙ‹Ø§)ØŒ Ù…Ù…Ø§ ÙŠØ¹Ù†ÙŠ Ø²ÙŠØ§Ø¯Ø© Ø³Ø±ÙŠØ¹Ø© ÙˆÙ…Ø³ØªÙ…Ø±Ø© ÙÙŠ Ø¹Ø¯Ø¯ Ø§Ù„Ø³ÙƒØ§Ù† ØªÙ„ØªÙ‡Ù… Ù…ÙƒØ§Ø³Ø¨ Ø§Ù„ØªÙ†Ù…ÙŠØ©.

Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬ØºØ±Ø§ÙÙŠ: ØªØ±ÙƒÙŠØ² Ø´Ø¯ÙŠØ¯ Ø­ÙˆÙ„ Ø§Ù„Ù†ÙŠÙ„ ÙˆØ§ØªØ¬Ø§Ù‡ Ù…ØªØ²Ø§ÙŠØ¯ Ù„Ù„Ø¹Ù…Ø±Ù†Ø© (Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¯Ù†)ØŒ Ø­ÙŠØ« ÙŠØ¹ÙŠØ´ Ù†Ø­Ùˆ 43% Ù…Ù† Ø§Ù„Ø³ÙƒØ§Ù† ÙÙŠ Ù…Ù†Ø§Ø·Ù‚ Ø­Ø¶Ø±ÙŠØ©.

Ø§Ù„ØªÙƒÙˆÙŠÙ† Ø§Ù„Ø«Ù‚Ø§ÙÙŠ: Ù…ØªØ¬Ø§Ù†Ø³ Ø¥Ù„Ù‰ Ø­Ø¯ ÙƒØ¨ÙŠØ±ØŒ Ø­ÙŠØ« ÙŠØ´ÙƒÙ„ Ø§Ù„Ù…Ø³Ù„Ù…ÙˆÙ† Ø§Ù„ØºØ§Ù„Ø¨ÙŠØ© Ø§Ù„Ø¹Ø¸Ù…Ù‰ (90-95%)ØŒ ÙˆÙŠØ´ÙƒÙ„ Ø§Ù„Ø£Ù‚Ø¨Ø§Ø· Ø§Ù„Ø£Ø±Ø«ÙˆØ°ÙƒØ³ Ù…Ø¹Ø¸Ù… Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©.

Ø§Ù„ØªØ­Ø¯ÙŠ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ: ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø·Ø§Ù‚Ø© Ø§Ù„Ø¨Ø´Ø±ÙŠØ© (Ø§Ù„Ø´Ø¨Ø§Ø¨) Ù…Ù† Ø¹Ø¨Ø¡ Ø¥Ù„Ù‰ Ø¹Ø§Ø¦Ø¯ Ø¯ÙŠÙ…ÙˆØºØ±Ø§ÙÙŠ Ù…Ù† Ø®Ù„Ø§Ù„ ØªÙˆÙÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø¬ÙŠØ¯ØŒ Ø§Ù„Ø±Ø¹Ø§ÙŠØ© Ø§Ù„ØµØ­ÙŠØ©ØŒ ÙˆÙØ±Øµ Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ù…Ù†ØªØ¬.